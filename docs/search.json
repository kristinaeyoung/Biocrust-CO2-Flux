[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biocrust CO₂ Flux Data From Precipitation Manipulation Experiment (Moab, UT)",
    "section": "",
    "text": "experiment_1_cummulative_flux_analysis.Rmd\ndata/: experiment_1_flux_curve.csv This R Markdown file reproduces Figure 2 and Table S1 from the manuscript. It contains data analysis and visualizations that assess how cumulative gross primary productivity (GPP) of biocrust communities responds to varying experimental precipitation pulse Purpose: The script models and visualizes the cumulative GPP of different biocrust types (Type, e.g., moss and cyano) under a gradient of watering treatments (Treat, in mm). The goal is to understand how biocrusts functionally respond to precipitation variability—a key question in dryland ecosystem research.\nR Packages Used: library(ggplot2) library(tidyr) library(tidyverse) library(sjPlot) library(car)\ndata/: experiment_1_flux_curve.csv This R Markdown file contains an analysis of CO₂ flux data collected by Young et al. during a precipitation pulse experiment. The goal is to explore and visualize how different biocrust types (cyanobacteria and moss) respond to varying watering treatments over time, using generalized additive models (GAMs) and mixed-effects models. Purpose: Model GPP (Gross Primary Productivity) responses across time, treatment levels, and crust types. Visualize modeled and observed flux dynamics (Figure 1). Conduct post-hoc analysis to compare patterns between biocrust types and treatments\nR Packages Used: library(ggplot2) library(tidyr) library(tidyverse) library(mgcv) library(lme4) library(sjPlot) library(car) library(multcomp) library(emmeans) library(cowplot) library(multcompView)"
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Biocrust CO₂ Flux Data From Precipitation Manipulation Experiment (Moab, UT)",
    "section": "Description",
    "text": "Description\nThis repository contains data and analysis code for a precipitation manipulation experiment conducted in Moab, Utah. The focus is on the effects of altered precipitation patterns on biocrust CO₂ fluxes. The dataset includes chamber-based flux measurements along with associated environmental variables.\nAll code and data are organized for reproducibility using R and the renv package for environment management."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Biocrust CO₂ Flux Data From Precipitation Manipulation Experiment (Moab, UT)",
    "section": "Getting Started",
    "text": "Getting Started\nTo get started with the project, follow these steps:\n\n1. Clone the repository\ngit clone https://github.com/kristinaeyoung/Biocrust-CO2-Flux.git\n\n\n2. Initialize R Environment\nThis project uses renv to manage R package dependencies.\nIn R:\ninstall.packages(“renv”) renv::restore() # This will install all required packages listed in renv.lock\n\n\nHow to Run the Analysis\nThe primary analysis is done through R Markdown files.\n\n\nMain Analysis File\nOpen and knit the following R Markdown file to reproduce the main analyses:"
  },
  {
    "objectID": "index.html#experiment_2_dry_down_curve_analysis.rmd",
    "href": "index.html#experiment_2_dry_down_curve_analysis.rmd",
    "title": "Biocrust CO₂ Flux Data From Precipitation Manipulation Experiment (Moab, UT)",
    "section": "experiment_2_dry_down_curve_analysis.Rmd",
    "text": "experiment_2_dry_down_curve_analysis.Rmd\ndata/: experiment_2_dry_down_curve_1 data/: experiment_2_dry_down_curve_2 This R Markdown file supports Figure S3 and calculates values for Figure S2 in the manuscript. It analyzes dry down curves for biocrust mesocosms over a four-month precipitation pulse experiment. The goal is to quantify drying dynamics, including wet duration, proportion of time wet, and dry down rate, across crust types and watering treatments. Purpose: Compile and calibrate water content data from biocrust mesocosms. Calculate and summarize hydrological response metrics: duration of wetting events, cumulative wet time, peak counts. Fit exponential decay models (DRC) to dry down curves by treatment and biocrust type. Compare drying rates of moss vs. cyanobacteria under different watering regimes R Packages Used: library(pracma) # for peak detection library(drc) # for exponential decay model fitting"
  },
  {
    "objectID": "index.html#experiment_2_initial_final_flux_analysis.rmd",
    "href": "index.html#experiment_2_initial_final_flux_analysis.rmd",
    "title": "Biocrust CO₂ Flux Data From Precipitation Manipulation Experiment (Moab, UT)",
    "section": "experiment_2_initial_final_flux_analysis.Rmd",
    "text": "experiment_2_initial_final_flux_analysis.Rmd\ndata/: experiment_2_initial_final_flux.csv This R Markdown file supports Figure 3 and Table S2 of the manuscript. It analyzes CO₂ fluxes—including Net Soil Exchange (NSE), Gross Primary Productivity (GPP), and Respiration—from biocrust communities subjected to varying precipitation pulse treatments. The analysis compares initial and final responses over the course of the experiment. Purpose: Compare initial vs. final CO₂ flux responses (NSE, GPP, Respiration). Assess how biocrust type (moss, cyano) and watering treatment (mm) influence fluxes. Fit and evaluate linear models for each flux metric at each timepoint. Visualize interactions using faceted plots R Packages Used: library(tidyr) library(ggplot2) library(tidyverse) library(mgcv) library(lme4) library(sjPlot) library(car)\nFile Structure data/: Raw and processed data files\nscripts/: Supporting R scripts\nrenv/ and renv.lock: R environment files\nNotes Be sure to have R ≥ 4.1 installed\nIf new packages are installed, run renv::snapshot() to update the environment"
  },
  {
    "objectID": "experiment_1_cummulative_flux_analysis.html",
    "href": "experiment_1_cummulative_flux_analysis.html",
    "title": "experiment_1_cummulative_flux_analysis",
    "section": "",
    "text": "This code corresponds to Figure 2 and Table S1 in the manuscript It’s purpose is to graph and model the cumulative GPP of different biocrust types (Type) given different experimental precipitation pulses (Treat)\n\n\nCode\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(car)\n\n\nRead in the data\n\n\nCode\ndata &lt;- read_csv(\"experiment_1_flux_curve.csv\") %&gt;% \n  mutate(Treat = as.numeric(Treat), Type = as.factor(Type))  # Convert Treat to numeric and Type to factor\n\n\nRows: 191 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Type\ndbl (15): Treat, Rep, Time, NSE_Lin_Flux, Lin_FluxCV, Exp_Flux, Exp_FluxCV, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nExclude NAs and summarize GPP by Type, Treat, and Rep\n\n\nCode\nsum &lt;- data %&gt;%\n  filter(!is.na(GPP_positive)) %&gt;%  # Exclude rows with NA in GPP_positive\n  group_by(Type, Treat, Rep) %&gt;%\n  summarize(sumGPP = sum(GPP_positive), .groups = 'drop')  # Sum GPP for each group\n\n\nModel the data\n\n\nCode\nlm_model &lt;- lm(sumGPP ~ Treat * Type, data = sum, na.action = na.exclude)\nsummary(lm_model)  # Check the summary of the model\n\n\n\nCall:\nlm(formula = sumGPP ~ Treat * Type, data = sum, na.action = na.exclude)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1559 -1.1793  0.0792  0.4279  2.3811 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     5.17197    0.72223   7.161 1.32e-07 ***\nTreat          -0.07171    0.11449  -0.626   0.5366    \nTypemoss        0.53061    1.02138   0.519   0.6078    \nTreat:Typemoss  0.43421    0.16191   2.682   0.0126 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.354 on 26 degrees of freedom\nMultiple R-squared:  0.6362,    Adjusted R-squared:  0.5943 \nF-statistic: 15.16 on 3 and 26 DF,  p-value: 6.65e-06\n\n\nCode\ntab_model(lm_model)\n\n\n\n\n\n \nsumGPP\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n5.17\n3.69 – 6.66\n&lt;0.001\n\n\nTreat\n-0.07\n-0.31 – 0.16\n0.537\n\n\nType [moss]\n0.53\n-1.57 – 2.63\n0.608\n\n\nTreat × Type [moss]\n0.43\n0.10 – 0.77\n0.013\n\n\nObservations\n30\n\n\nR2 / R2 adjusted\n0.636 / 0.594\n\n\n\n\n\n\n\nCheck model assumptions\n\nNormality of residuals\n\n\n\nCode\nresiduals &lt;- residuals(lm_model)\nshapiro_test &lt;- shapiro.test(residuals)  # Shapiro-Wilk test for normality\nprint(shapiro_test)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals\nW = 0.94883, p-value = 0.1573\n\n\nresiduals are normally distributed according to Shapiro-Wilk test\nPlot residuals\n\n\nCode\nggplot(data = data.frame(residuals = residuals), aes(x = residuals)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\")\n\n\n\n\n\nresiduals are roughly bell-shaped and do not show significant skew\n\nHomogeneity of variance\n\nLevene’s test requires a formula that includes the grouping variable\n\n\nCode\nlevene_test &lt;- leveneTest(sumGPP ~ Type, data = sum)  # Test for homogeneity of variances across Types\nprint(levene_test)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  1.3858  0.249\n      28               \n\n\nAssumptions of homogeneity of variance hold\nPlot diagnostic plots for ANOVA\n\n\nCode\npar(mfrow = c(2, 2))\nplot(lm_model)\n\n\n\n\n\nresiduals vs fitted show no clear pattern residuals fall along 45-degree angle random spread of points a few lines are outside of Cook’s distance line, but not too abd\nPlot data with linear model\n\n\nCode\nggplot(sum, aes(x = Treat, y = sumGPP, color = Type, shape = Type)) + \n  geom_point(size = 3, position = position_jitter(width = 0.2, height = 0)) + # Points with jitter\n  geom_smooth(method = \"lm\", aes(group = Type), se = TRUE) +  # Linear model with confidence interval\n  ylab('Total measured GPP (µmol CO2/m²/s)') +\n  xlab('Watering amount (mm)') +\n  scale_color_manual(values = c(\"#fdbb84\", \"#2ca25f\")) +  # Custom colors for Type\n  scale_shape_manual(values = c(\"moss\" = 17, \"cyano\" = 16)) +\n  scale_x_continuous(breaks = c(1.8, 2.7, 5.4, 7.7, 10)) +  # Custom x-axis tick marks\n  theme_bw() +\n  theme(axis.title.x = element_text(size = 12),\n        axis.text.x = element_text(size = 12),\n        axis.title.y = element_text(size = 12),\n        axis.text.y = element_text(size = 12),\n        panel.grid.major = element_blank(),\n        axis.line = element_line(colour = \"black\"),\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 16))\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "experiment_1_flux_curve_analysis.html#minus-60-gpp",
    "href": "experiment_1_flux_curve_analysis.html#minus-60-gpp",
    "title": "210_minus_60_GPP",
    "section": "201 minus 60 GPP",
    "text": "201 minus 60 GPP\nThis R Markdown will track the analysis of GPP data collected by Young et al. First step will be to load the libraries and the data.\n\n\nCode\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(tidyverse)\nlibrary(mgcv)\nlibrary(lme4)\nlibrary(sjPlot)\nlibrary(car)\nlibrary(multcomp)\nlibrary(emmeans)\nlibrary(cowplot)\nlibrary(multcompView)\n\n\nBecause this is an R markdown file, the working directory is set to where ever this is saved.\n\n\nCode\ndata &lt;- read_csv(\"experiment_1_flux_curve.csv\") %&gt;% \n  mutate(Treat = as.numeric(Treat), Type = as.factor(Type))  # Convert Treat to numeric and Type to factor\n\n\nRows: 191 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Type\ndbl (15): Treat, Rep, Time, NSE_Lin_Flux, Lin_FluxCV, Exp_Flux, Exp_FluxCV, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ndata&lt;-data %&gt;% \n  mutate(Treat=as.factor(Treat), Type=as.factor(Type)) %&gt;% #creates variables into factors for analysis\n  mutate(Time = case_when(\n    Time == 1 ~ 30,\n    Time == 2 ~ 60,\n    Time == 3 ~ 90,\n    Time == 4 ~ 120,\n    Time == 5 ~ 150,\n    Time == 6 ~ 180,\n    Time == 7 ~ 210))"
  },
  {
    "objectID": "experiment_1_flux_curve_analysis.html#building-gam-for-comparing-crust-type-and-water-type",
    "href": "experiment_1_flux_curve_analysis.html#building-gam-for-comparing-crust-type-and-water-type",
    "title": "210_minus_60_GPP",
    "section": "BUilding GAM for comparing crust type and water type",
    "text": "BUilding GAM for comparing crust type and water type\nThe objective of these analyses is to compare CO2 response rats of cyanobacteria and moss to different watering treatments (Treat). Original models were built by Kristin Young.\n\n\nCode\nmodel_1&lt;- gam(GPP_positive ~ Type * Treat + s(Time, by = Treat, k = 2) +\n               s(Rep, bs = 're'), \n             data = data, family=gaussian)\n\n\nWarning in smooth.construct.tp.smooth.spec(object, dk$data, dk$knots): la dimension de base, k, est augmentée à la valeur minimale possible\n\n\nCode\nmodel_2&lt;- gam(GPP_positive ~ Type * Treat + s(Time, by = Treat, k = 4) +s(Time, by = Type, k = 4) +\n               s(Rep, bs = 're'), \n             data = data, family=gaussian) \n\nmodel_3&lt;- gam(GPP_positive ~ Type * Treat +s(Time, by = Type, k = 4) +\n               s(Rep, bs = 're'), \n             data = data, family=gaussian) \n\nAIC(model_1, model_2, model_3)## model 2 is lower AIC\n\n\n              df       AIC\nmodel_1 17.84123 106.69568\nmodel_2 20.63656  93.54248\nmodel_3 15.57728 109.62824\n\n\nCode\nsummary(model_2)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nGPP_positive ~ Type * Treat + s(Time, by = Treat, k = 4) + s(Time, \n    by = Type, k = 4) + s(Rep, bs = \"re\")\n\nParametric coefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        0.66872    0.06567  10.182  &lt; 2e-16 ***\nTypemoss           0.23416    0.09251   2.531  0.01227 *  \nTreat2.7           0.24618    0.09205   2.674  0.00821 ** \nTreat5.4           0.01917    0.09572   0.200  0.84150    \nTreat7.7           0.04351    0.09572   0.455  0.65000    \nTreat10            0.11359    0.09776   1.162  0.24686    \nTypemoss:Treat2.7 -0.06209    0.12915  -0.481  0.63128    \nTypemoss:Treat5.4  0.31519    0.13516   2.332  0.02087 *  \nTypemoss:Treat7.7  0.56461    0.13516   4.178  4.7e-05 ***\nTypemoss:Treat10   0.37295    0.13642   2.734  0.00692 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                        edf Ref.df      F  p-value    \ns(Time):Treat1.8  2.048e+00 2.4262  5.529 0.002053 ** \ns(Time):Treat2.7  2.427e+00 2.7142  5.794 0.024934 *  \ns(Time):Treat5.4  8.571e-01 0.8571  1.580 0.246146    \ns(Time):Treat7.7  8.571e-01 0.8571  1.596 0.243852    \ns(Time):Treat10   8.571e-01 0.8571  3.302 0.094361 .  \ns(Time):Typecyano 8.571e-01 0.8571 14.208 0.000616 ***\ns(Time):Typemoss  1.733e+00 2.1096 22.530  &lt; 2e-16 ***\ns(Rep)            3.238e-10 1.0000  0.000 0.507501    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nRank: 31/32\nR-sq.(adj) =  0.664   Deviance explained = 69.7%\nGCV = 0.095886  Scale est. = 0.085976  n = 190\n\n\nCode\nplot(model_2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nanova(model_2)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nGPP_positive ~ Type * Treat + s(Time, by = Treat, k = 4) + s(Time, \n    by = Type, k = 4) + s(Rep, bs = \"re\")\n\nParametric Terms:\n           df     F  p-value\nType        1 6.407   0.0123\nTreat       4 2.324   0.0586\nType:Treat  4 7.566 1.24e-05\n\nApproximate significance of smooth terms:\n                        edf    Ref.df      F  p-value\ns(Time):Treat1.8  2.048e+00 2.426e+00  5.529 0.002053\ns(Time):Treat2.7  2.427e+00 2.714e+00  5.794 0.024934\ns(Time):Treat5.4  8.571e-01 8.571e-01  1.580 0.246146\ns(Time):Treat7.7  8.571e-01 8.571e-01  1.596 0.243852\ns(Time):Treat10   8.571e-01 8.571e-01  3.302 0.094361\ns(Time):Typecyano 8.571e-01 8.571e-01 14.208 0.000616\ns(Time):Typemoss  1.733e+00 2.110e+00 22.530  &lt; 2e-16\ns(Rep)            3.238e-10 1.000e+00  0.000 0.507501\n\n\nCode\ntab_model(model_2)# R2=0.664, can use this output in MS to explain model observations\n\n\n\n\n\n\n\n\n\n\n\n \nGPP_positive\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n0.67\n0.54 – 0.80\n&lt;0.001\n\n\nTypemoss\n0.23\n0.05 – 0.42\n0.012\n\n\nTreat2 7\n0.25\n0.06 – 0.43\n0.008\n\n\nTreat5 4\n0.02\n-0.17 – 0.21\n0.841\n\n\nTreat7 7\n0.04\n-0.15 – 0.23\n0.650\n\n\nTreat10\n0.11\n-0.08 – 0.31\n0.247\n\n\nTypemoss × Treat2 7\n-0.06\n-0.32 – 0.19\n0.631\n\n\nTypemoss × Treat5 4\n0.32\n0.05 – 0.58\n0.021\n\n\nTypemoss × Treat7 7\n0.56\n0.30 – 0.83\n&lt;0.001\n\n\nTypemoss × Treat10\n0.37\n0.10 – 0.64\n0.007\n\n\nSmooth term (Time) ×\nTreat1 8\n\n\n0.002\n\n\nSmooth term (Time) ×\nTreat2 7\n\n\n0.025\n\n\nSmooth term (Time) ×\nTreat5 4\n\n\n0.246\n\n\nSmooth term (Time) ×\nTreat7 7\n\n\n0.244\n\n\nSmooth term (Time) ×\nTreat10\n\n\n0.094\n\n\nSmooth term (Time) ×\nTypecyano\n\n\n0.001\n\n\nSmooth term (Time) ×\nTypemoss\n\n\n&lt;0.001\n\n\nSmooth term (Rep)\n\n\n0.508\n\n\nObservations\n190\n\n\nR2\n0.664\n\n\n\n\n\n\n\nCode\ngam.check(model_2) #model looks really good with assumptions\n\n\n\n\n\n\nMethod: GCV   Optimizer: magic\nSmoothing parameter selection converged after 14 iterations.\nThe RMS GCV score gradient at convergence was 1.339272e-08 .\nThe Hessian was positive definite.\nModel rank =  31 / 32 \n\nBasis dimension (k) checking results. Low p-value (k-index&lt;1) may\nindicate that k is too low, especially if edf is close to k'.\n\n                        k'      edf k-index p-value\ns(Time):Treat1.8  3.00e+00 2.05e+00    1.12    0.92\ns(Time):Treat2.7  3.00e+00 2.43e+00    1.12    0.93\ns(Time):Treat5.4  3.00e+00 8.57e-01    1.12    0.92\ns(Time):Treat7.7  3.00e+00 8.57e-01    1.12    0.94\ns(Time):Treat10   3.00e+00 8.57e-01    1.12    0.94\ns(Time):Typecyano 3.00e+00 8.57e-01    1.12    0.95\ns(Time):Typemoss  3.00e+00 1.73e+00    1.12    0.92\ns(Rep)            1.00e+00 3.24e-10    1.15    0.97\n\n\nCode\n#Anova(model_2)\n\n\nThe model looks pretty good and is explaining about 70% of the variation in the data. To help with interpretation, we can now build out predictive models so we can plot our model output and see how it looks."
  },
  {
    "objectID": "experiment_1_flux_curve_analysis.html#build-models-and-think-about-stats-tables",
    "href": "experiment_1_flux_curve_analysis.html#build-models-and-think-about-stats-tables",
    "title": "210_minus_60_GPP",
    "section": "Build models and think about stats tables",
    "text": "Build models and think about stats tables\n\n\nCode\npredict&lt;-tidymv::predict_gam(model_2) \n\n#test plot of the curves from the model\npredict %&gt;% \n  ggplot(aes(x = Time, y = fit, color = Type))+\n  geom_smooth(method=\"gam\", formula=y~s(x))+\n  facet_grid(. ~ Treat, scales = 'free') \n\n\n\n\n\nTrying to figure out how to remove the gaps in the confidence intervals.\nNext step is to clean up the plot and bring it all together.\n\n\nCode\ngraph_df&lt;-predict%&gt;% #first need to merge in the predictive data\n   mutate(lwr=fit-(2*se.fit), upr=fit+(2*se.fit))\n\n(fig1&lt;-\n  ggplot()+\n    geom_ribbon(data=graph_df, aes(x=Time, ymin=lwr, ymax= upr, group=Type),  fill=\"gray\")+\n  stat_smooth(data=graph_df, aes(x=Time, y=fit, color=Type), method=\"gam\", formula=y~s(x), se=T)+\n    geom_point(data=data,aes(x=Time, y= GPP_positive, color = Type, shape= Type))+\n   facet_grid(. ~ Treat, scales = 'free') + \n  ylab('GPP (µmol CO2/m²/s)') +\n  xlab('Time (minutes)') +\n  scale_color_manual( \"Crust Type\", values = c(\"#fdbb84\", \"#2ca25f\")) +\n    scale_shape_manual( \"Crust Type\", values = c(16,17)) +\n  scale_x_continuous(breaks=seq(0, 210, 30))+\n  theme_bw() +\n  theme(axis.title.x=element_text(size=12),\n       axis.text.x = element_text(angle = 30, hjust = 1, size=9, color = \"black\"),\n        axis.title.y=element_text(size=12),\n        axis.text.y=element_text(size=12),\n        panel.grid.major = element_blank(),\n        axis.line = element_line(colour = \"black\"),\n        legend.title=element_text(size=12),\n        legend.text=element_text(size=12))\n )\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nCode\nfig1\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nCode\nggsave(\"fig1.png\", dpi=300, width=8, height=5.5, units=\"in\")\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nFigure out the stats for this above figure and make a table. Are the patterns different between moss and cyano overtime within each treatment? I think the best option is to fit a linear mixed effects model and then do post-hoc testing with the multcomp package.\n\n\nCode\nmodel_2&lt;- gam(GPP_positive ~ Type * Treat + s(Time, by = Treat, k = 4) +\n                s(Time, by = Type, k = 4) +\n               s(Rep, bs = 're'), \n             data = data, family=gaussian) \n\nmod_posthoc&lt;-lme4::lmer(GPP_positive~Type*Treat+(1|Rep), data=data)\n\n\nboundary (singular) fit: see help('isSingular')\n\n\nCode\nsummary(mod_posthoc)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: GPP_positive ~ Type * Treat + (1 | Rep)\n   Data: data\n\nREML criterion at convergence: 223.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9599 -0.6429  0.1768  0.6391  2.3270 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Rep      (Intercept) 0.0000   0.0000  \n Residual             0.1725   0.4154  \nNumber of obs: 190, groups:  Rep, 3\n\nFixed effects:\n                  Estimate Std. Error t value\n(Intercept)        0.63606    0.09064   7.017\nTypemoss           0.23379    0.12978   1.801\nTreat2.7           0.22455    0.12819   1.752\nTreat5.4           0.07666    0.13342   0.575\nTreat7.7           0.10104    0.13342   0.757\nTreat10            0.19429    0.13552   1.434\nTypemoss:Treat2.7 -0.09427    0.18242  -0.517\nTypemoss:Treat5.4  0.33904    0.18977   1.787\nTypemoss:Treat7.7  0.58846    0.18977   3.101\nTypemoss:Treat10   0.37734    0.19125   1.973\n\nCorrelation of Fixed Effects:\n            (Intr) Typmss Trt2.7 Trt5.4 Trt7.7 Tret10 T:T2.7 T:T5.4 T:T7.7\nTypemoss    -0.698                                                        \nTreat2.7    -0.707  0.494                                                 \nTreat5.4    -0.679  0.474  0.480                                          \nTreat7.7    -0.679  0.474  0.480  0.462                                   \nTreat10     -0.669  0.467  0.473  0.454  0.454                            \nTypmss:T2.7  0.497 -0.711 -0.703 -0.338 -0.338 -0.332                     \nTypmss:T5.4  0.478 -0.684 -0.338 -0.703 -0.324 -0.319  0.487              \nTypmss:T7.7  0.478 -0.684 -0.338 -0.324 -0.703 -0.319  0.487  0.468       \nTypmss:Tr10  0.474 -0.679 -0.335 -0.322 -0.322 -0.709  0.483  0.464  0.464\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nCode\nAnova(mod_posthoc)\n\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: GPP_positive\n            Chisq Df Pr(&gt;Chisq)    \nType       57.783  1  2.927e-14 ***\nTreat      23.572  4  9.731e-05 ***\nType:Treat 17.954  4    0.00126 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nemm = emmeans(mod_posthoc, ~ Type*Treat)\npairs(emm)\n\n\n contrast                        estimate    SE  df t.ratio p.value\n cyano Treat1.8 - moss Treat1.8  -0.23379 0.130 179  -1.798  0.7356\n cyano Treat1.8 - cyano Treat2.7 -0.22455 0.128 178  -1.750  0.7649\n cyano Treat1.8 - moss Treat2.7  -0.36406 0.128 178  -2.838  0.1320\n cyano Treat1.8 - cyano Treat5.4 -0.07666 0.134 178  -0.574  0.9999\n cyano Treat1.8 - moss Treat5.4  -0.64948 0.134 178  -4.864  0.0001\n cyano Treat1.8 - cyano Treat7.7 -0.10104 0.134 178  -0.757  0.9990\n cyano Treat1.8 - moss Treat7.7  -0.92329 0.134 178  -6.915  &lt;.0001\n cyano Treat1.8 - cyano Treat10  -0.19429 0.136 179  -1.431  0.9159\n cyano Treat1.8 - moss Treat10   -0.80541 0.134 178  -6.032  &lt;.0001\n moss Treat1.8 - cyano Treat2.7   0.00924 0.130 178   0.071  1.0000\n moss Treat1.8 - moss Treat2.7   -0.13028 0.130 178  -1.004  0.9917\n moss Treat1.8 - cyano Treat5.4   0.15713 0.135 178   1.164  0.9767\n moss Treat1.8 - moss Treat5.4   -0.41569 0.135 178  -3.080  0.0709\n moss Treat1.8 - cyano Treat7.7   0.13275 0.135 178   0.983  0.9929\n moss Treat1.8 - moss Treat7.7   -0.68950 0.135 178  -5.108  &lt;.0001\n moss Treat1.8 - cyano Treat10    0.03950 0.137 178   0.288  1.0000\n moss Treat1.8 - moss Treat10    -0.57162 0.135 178  -4.235  0.0015\n cyano Treat2.7 - moss Treat2.7  -0.13952 0.128 178  -1.088  0.9853\n cyano Treat2.7 - cyano Treat5.4  0.14789 0.133 178   1.108  0.9833\n cyano Treat2.7 - moss Treat5.4  -0.42494 0.133 178  -3.185  0.0529\n cyano Treat2.7 - cyano Treat7.7  0.12351 0.133 178   0.926  0.9954\n cyano Treat2.7 - moss Treat7.7  -0.69874 0.133 178  -5.237  &lt;.0001\n cyano Treat2.7 - cyano Treat10   0.03026 0.136 178   0.223  1.0000\n cyano Treat2.7 - moss Treat10   -0.58087 0.133 178  -4.354  0.0009\n moss Treat2.7 - cyano Treat5.4   0.28741 0.133 178   2.154  0.4923\n moss Treat2.7 - moss Treat5.4   -0.28542 0.133 178  -2.139  0.5026\n moss Treat2.7 - cyano Treat7.7   0.26303 0.133 178   1.971  0.6201\n moss Treat2.7 - moss Treat7.7   -0.55922 0.133 178  -4.191  0.0017\n moss Treat2.7 - cyano Treat10    0.16978 0.136 178   1.252  0.9625\n moss Treat2.7 - moss Treat10    -0.44135 0.133 178  -3.308  0.0369\n cyano Treat5.4 - moss Treat5.4  -0.57282 0.138 178  -4.137  0.0022\n cyano Treat5.4 - cyano Treat7.7 -0.02438 0.138 178  -0.176  1.0000\n cyano Treat5.4 - moss Treat7.7  -0.84663 0.138 178  -6.115  &lt;.0001\n cyano Treat5.4 - cyano Treat10  -0.11763 0.141 178  -0.837  0.9979\n cyano Treat5.4 - moss Treat10   -0.72875 0.138 178  -5.263  &lt;.0001\n moss Treat5.4 - cyano Treat7.7   0.54845 0.138 178   3.961  0.0042\n moss Treat5.4 - moss Treat7.7   -0.27381 0.138 178  -1.978  0.6159\n moss Treat5.4 - cyano Treat10    0.45520 0.141 178   3.239  0.0452\n moss Treat5.4 - moss Treat10    -0.15593 0.138 178  -1.126  0.9814\n cyano Treat7.7 - moss Treat7.7  -0.82225 0.138 178  -5.939  &lt;.0001\n cyano Treat7.7 - cyano Treat10  -0.09325 0.141 178  -0.664  0.9997\n cyano Treat7.7 - moss Treat10   -0.70437 0.138 178  -5.087  &lt;.0001\n moss Treat7.7 - cyano Treat10    0.72900 0.141 178   5.188  &lt;.0001\n moss Treat7.7 - moss Treat10     0.11788 0.138 178   0.851  0.9976\n cyano Treat10 - moss Treat10    -0.61112 0.141 178  -4.349  0.0009\n\nDegrees-of-freedom method: kenward-roger \nP value adjustment: tukey method for comparing a family of 10 estimates \n\n\nCode\nmodel_means_cld &lt;- cld(object = emm,\n                       adjust = \"Tukey\",\n                       Letters = letters,\n                       alpha = 0.05)\n\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\n\n\nCode\nmodel_means_cld\n\n\n Type  Treat emmean     SE    df lower.CL upper.CL .group\n cyano 1.8    0.636 0.0908  93.3    0.376    0.896  a    \n cyano 5.4    0.713 0.0979 109.9    0.433    0.992  a    \n cyano 7.7    0.737 0.0979 109.9    0.457    1.017  a    \n cyano 10     0.830 0.1008 114.7    0.543    1.118  a    \n cyano 2.7    0.861 0.0906  94.6    0.601    1.120  ab   \n moss  1.8    0.870 0.0929  99.0    0.604    1.136  ab   \n moss  2.7    1.000 0.0906  94.6    0.740    1.260  ab   \n moss  5.4    1.286 0.0979 109.9    1.006    1.565   bc  \n moss  10     1.441 0.0979 109.9    1.162    1.721    c  \n moss  7.7    1.559 0.0979 109.9    1.280    1.839    c  \n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 10 estimates \nP value adjustment: tukey method for comparing a family of 10 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "experiment_2_dry_down_curve_analysis.html",
    "href": "experiment_2_dry_down_curve_analysis.html",
    "title": "experiment_2_dry_down_curve_analysis",
    "section": "",
    "text": "This code corresponds to Figure S3 and calculates values for Figure S2 The purpose of this code is to compile, analyze, and graph the dry down curves for each biocrust and treatment type over the four month pulse manipulation experiment\n\n\nCode\nlibrary(\"pracma\")\nlibrary(\"drc\")\n\n\nLe chargement a nécessité le package : MASS\n\n\n\n'drc' has been loaded.\n\n\nPlease cite R and 'drc' if used for a publication,\n\n\nfor references type 'citation()' and 'citation('drc')'.\n\n\n\nAttachement du package : 'drc'\n\n\nLes objets suivants sont masqués depuis 'package:stats':\n\n    gaussian, getInitial\n\n\nInput crust mesocosm data\n\n\nCode\npulse &lt;- read.csv(\"experiment_2_dry_down_curve_1.csv\",header=T)\npulse$TIMESTAMP &lt;- as.POSIXct(as.character(pulse$TIMESTAMP),format=\"%m/%d/%Y %H:%M\")\n\npulse[,2:29][pulse[,2:29]&gt;30] &lt;- 0\npar(mfrow=c(2,4))\nmaxS &lt;- c()\nminS &lt;- c()\nsdminS &lt;- c()\ncounts &lt;- c()\n\n\nmin and maxWC from some calibrations Armin and I did, for “calibration” to GWC\n\n\nCode\nmaxWC &lt;- c(0.32,0.76)\nminWC &lt;- c(0.018,0.045)\n\n\nmerging\n\n\nCode\ntreatments &lt;- read.csv(\"experiment_2_dry_down_curve_2.csv\")\ntreatments &lt;- treatments[-c(1,16),]\ntreat &lt;-treatments$Treatment\nbc &lt;- treatments$Type\n\n\nnumber of events there should be in a data set\n\n\nCode\ncounts &lt;-ifelse(treat==1.8,36,ifelse(treat==2.7,26,ifelse(treat==5.4,13,ifelse(treat==7.7,9,ifelse(treat==10.0,7,NA)))))\n\n\nrescaling between max and min WC for “calibration”\n\n\nCode\nrescaleF &lt;- function(min,max,vwcmin,vwcmax,input){\n  output &lt;- ((input - min)*(vwcmax - vwcmin)/(max-min)) + vwcmin\n  return(output)\n}\n\n\nfind average min of lowest 6000 measurements and max peak heights separated by at leat 144 measurements\n\n\nCode\nfor (i in 2:29){\n  tryCatch({\n    #plot(pulse[,i],type=\"l\",main=i)\n    #abline(h=0.2)\n    print(findpeaks(na.omit(pulse[,i]),nups = 1,ndowns = 1,minpeakheight = 0.3,minpeakdistance = 144))\n    minS[i-1] &lt;- mean(pulse[order(pulse[,i]),i][1:6000],na.rm=T)\n    sdminS[i-1] &lt;- sd(pulse[order(pulse[,i]),i][1:6000],na.rm=T)\n    maxS[i-1] &lt;- mean(findpeaks(na.omit(pulse[,i]),nups = 1,ndowns = 1,minpeakheight = 0.3,minpeakdistance = 144)[,1],na.rm=T)\n  }, error=function(e){})\n}\n\n\n       [,1]  [,2]  [,3]  [,4]\n [1,] 7.962   180   177   206\n [2,] 3.329   493   491   504\n [3,] 3.167  1914  1910  1923\n [4,] 2.410   910   906   912\n [5,] 2.071  1204  1197  1207\n [6,] 1.904  7243  7240  7257\n [7,] 1.458  7527  7525  7538\n [8,] 1.417  2204  2201  2215\n [9,] 1.199  2921  2919  2933\n[10,] 0.771  3931  3929  3939\n[11,] 0.640  4938  4936  4940\n[12,] 0.494 12008 12006 12009\n[13,] 0.484  7968  7966  7972\n       [,1]  [,2]  [,3]  [,4]\n [1,] 5.007  7099  7097  7111\n [2,] 4.891 11430 11428 11442\n [3,] 4.864   343   336   347\n [4,] 4.781  3065  3062  3075\n [5,] 4.781 12141 12139 12144\n [6,] 4.736  9409  9407  9435\n [7,] 4.699  3358  3356  3390\n [8,] 4.699  4367  4365  4373\n [9,] 4.667  7389  7387  7396\n[10,] 4.658  4075  4073  4086\n[11,] 4.594 11135 11133 11163\n[12,] 4.571  6378  6375  6407\n[13,] 4.534  9116  9114  9123\n[14,] 4.513  8405  8403  8423\n[15,] 4.397  6090  6088  6100\n[16,] 4.259  5080  5073  5084\n[17,] 4.137  5364  5362  5370\n[18,] 3.233  8110  8107  8115\n[19,] 3.162 10139 10135 10157\n[20,] 2.959 10417 10413 10423\n[21,] 2.666  2349  2347  2355\n[22,] 2.297  1387  1382  1389\n[23,] 2.052  2066  2061  2071\n[24,] 1.406 12431 12428 12433\n[25,] 1.398  1052  1050  1054\n[26,] 0.360    46    45    50\n       [,1]  [,2]  [,3]  [,4]\n [1,] 6.732    44    41    76\n [2,] 6.467  8407  8403  8423\n [3,] 5.565  1067  1062  1075\n [4,] 5.008  1386  1382  1396\n [5,] 4.452   331   329   340\n [6,] 4.430  7098  7096  7110\n [7,] 4.252  2065  2054  2067\n [8,] 4.000  4364  4362  4386\n [9,] 3.808  4076  4072  4090\n[10,] 3.808 12137 12134 12139\n[11,] 3.628  5080  5073  5082\n[12,] 3.443  7404  7402  7409\n[13,] 3.055  8109  8107  8115\n[14,] 2.440  3357  3354  3358\n[15,] 2.335  9119  9113  9121\n[16,] 2.224 11441 11439 11455\n[17,] 2.138 10133 10126 10143\n[18,] 2.113  9410  9407  9430\n[19,] 1.404 10424 10422 10428\n[20,] 1.111 11137 11132 11140\n[21,] 1.067  2353  2350  2367\n[22,] 0.504 12427 12425 12434\n        [,1]  [,2]  [,3]  [,4]\n [1,] 16.440   182   179   191\n [2,] 10.440 10273 10268 10280\n [3,] 10.280 11284 11279 11292\n [4,] 10.060  9273  9271  9305\n [5,]  9.500  8261  8259  8296\n [6,]  9.210 12567 12565 12571\n [7,]  8.090  7257  7255  7276\n [8,]  3.992  6234  6232  6268\n [9,]  3.384  4221  4218  4232\n[10,]  3.091  5221  5219  5224\n[11,]  3.054  1199  1197  1201\n[12,]  2.631  3215  3213  3221\n[13,]  1.901  1386  1382  1388\n[14,]  1.034  2217  2213  2220\n[15,]  0.605 11442 11441 11447\n        [,1]  [,2]  [,3]  [,4]\n [1,] 10.550  2219  2217  2220\n [2,]  8.640  1234  1232  1240\n [3,]  7.894  4226  4224  4227\n [4,]  7.417  1386  1383  1390\n [5,]  7.144  5219  5217  5221\n [6,]  6.789  3235  3232  3236\n [7,]  6.572 12572 12571 12573\n [8,]  6.230   182   180   183\n [9,]  6.098  9275  9274  9279\n[10,]  4.439  8257  8256  8259\n[11,]  2.055  7254  7253  7256\n[12,]  1.171 11394 11391 11398\n[13,]  1.035  2366  2365  2371\n[14,]  0.826 10275 10268 10278\n[15,]  0.730  1632  1631  1633\n       [,1]  [,2]  [,3]  [,4]\n [1,] 6.500   189   188   195\n [2,] 6.005 12284 12280 12288\n [3,] 5.724 10563 10561 10571\n [4,] 5.498  9257  9254  9265\n [5,] 4.315  7965  7964  7976\n [6,] 3.822  3215  3212  3221\n [7,] 2.495  1561  1560  1563\n [8,] 2.071  4506  4504  4517\n [9,] 1.736  6385  6383  6390\n[10,] 1.411  6238  6232  6242\n[11,] 0.519 10717 10710 10720\n        [,1]  [,2]  [,3]  [,4]\n [1,] 19.680 12286 12283 12289\n [2,] 14.260  6380  6375  6388\n [3,] 14.180 10568 10562 10588\n [4,] 13.890  9257  9254  9270\n [5,] 13.770  4510  4506  4541\n [6,] 12.800  7962  7957  7965\n [7,]  9.790  3218  3215  3219\n [8,]  8.190  1496  1492  1499\n [9,]  6.239   190   188   203\n[10,]  5.833  1642  1640  1643\n[11,]  2.578 12436 12435 12454\n[12,]  1.988 10713 10711 10716\n[13,]  0.945   342   340   343\n[14,]  0.792  4662  4661  4664\n[15,]  0.730  9404  9403  9405\n[16,]  0.697  3368  3367  3369\n[17,]  0.659 10859 10853 10862\n[18,]  0.654  2056  2054  2057\n[19,]  0.590  6526  6524  6528\n[20,]  0.561 12586 12584 12587\n[21,]  0.518 11409 11408 11410\n[22,]  0.486  1798  1796  1803\n[23,]  0.373  5078  5073  5080\n        [,1]  [,2]  [,3]  [,4]\n [1,] 29.260 10137 10134 10247\n [2,] 26.930  6380  6375  6384\n [3,] 23.250 12430 12427 12433\n [4,] 16.540  8401  8399  8405\n [5,] 13.330  4368  4366  4370\n [6,] 10.420   341   336   347\n [7,]  3.579  2350  2347  2353\n [8,]  1.581   514   511   515\n [9,]  0.719 12661 12658 12663\n[10,]  0.598 10390 10389 10392\n[11,]  0.504 11423 11422 11429\n        [,1]  [,2]  [,3]  [,4]\n [1,] 14.840 10132 10131 10153\n [2,] 12.040  4364  4362  4366\n [3,] 10.300  6384  6383  6388\n [4,]  9.110   328   327   336\n [5,]  8.720  8393  8391  8394\n [6,]  8.070 12423 12421 12426\n [7,]  7.009  2356  2350  2363\n [8,]  0.952  2501  2500  2502\n [9,]  0.518   494   493   501\n        [,1]  [,2]  [,3]  [,4]\n [1,] 10.280  7244  7238  7273\n [2,]  9.540  6233  6230  6267\n [3,]  9.400  5509  5505  5510\n [4,]  9.320  6955  6952  6961\n [5,]  8.470  7535  7532  7548\n [6,]  8.350  6524  6521  6554\n [7,]  7.823  3501  3499  3509\n [8,]  7.782  2922  2919  2930\n [9,]  7.768  1234  1231  1241\n[10,]  7.685   182   177   183\n[11,]  7.589   480   476   490\n[12,]  7.543  5228  5222  5269\n[13,]  7.451 12571 12569 12610\n[14,]  7.396  4222  4219  4225\n[15,]  7.076 12283 12280 12298\n[16,]  6.592 11281 11279 11285\n[17,]  6.204  8262  8259  8284\n[18,]  6.151 10277 10268 10291\n[19,]  6.101 10994 10992 11011\n[20,]  5.942  3932  3928  3940\n[21,]  5.742  8973  8970  8997\n[22,]  5.719  8538  8535  8568\n[23,]  5.702  4508  4503  4513\n[24,]  5.578  4942  4938  4944\n[25,]  5.497   921   917   924\n[26,]  5.492  1917  1909  1919\n[27,]  4.984  2493  2488  2499\n[28,]  4.929  9551  9548  9573\n[29,]  4.891 11566 11564 11602\n[30,]  4.714  9270  9268  9290\n[31,]  4.219  2216  2213  2220\n[32,]  4.164  9983  9981  9987\n[33,]  3.849 11993 11989 11996\n[34,]  3.384  3216  3214  3217\n[35,]  3.335  5967  5964  5984\n[36,]  2.926  1499  1497  1500\n[37,]  2.128  7963  7957  7967\n       [,1]  [,2]  [,3]  [,4]\n [1,] 7.554   492   491   496\n [2,] 5.757   180   178   193\n [3,] 4.452  8257  8255  8275\n [4,] 3.933  7963  7958  7967\n [5,] 3.753  4509  4507  4518\n [6,] 3.726  4220  4217  4225\n [7,] 3.685  7534  7533  7542\n [8,] 3.648  8538  8535  8545\n [9,] 3.227  7242  7240  7257\n[10,] 3.105  3931  3929  3940\n[11,] 3.000  5507  5505  5512\n[12,] 2.918  3501  3499  3506\n[13,] 2.864  2920  2918  2931\n[14,] 2.823   912   910   915\n[15,] 2.717  6523  6521  6529\n[16,] 2.624  5226  5224  5247\n[17,] 2.276  6954  6952  6963\n[18,] 2.263 12003 12000 12004\n[19,] 2.042  9551  9549  9564\n[20,] 1.792  2490  2488  2496\n[21,] 1.787  1919  1916  1923\n[22,] 1.758  3213  3211  3223\n[23,] 1.549  9269  9263  9277\n[24,] 1.454  5965  5964  5968\n[25,] 1.286  6233  6232  6238\n[26,] 1.254  2203  2200  2207\n[27,] 1.158  9982  9981  9989\n[28,] 0.940  4938  4937  4940\n[29,] 0.545  1500  1497  1501\n[30,] 0.540  1203  1197  1206\n[31,] 0.510  8974  8972  8976\n[32,] 0.502 12290 12289 12298\n[33,] 0.448 12584 12583 12585\n[34,] 0.433 11289 11283 11292\n[35,] 0.428 11583 11581 11584\n        [,1]  [,2]  [,3]  [,4]\n [1,] 15.000  6382  6375  6454\n [2,] 14.940  9263  9260  9274\n [3,] 14.890  7961  7957  7974\n [4,] 14.770  6238  6232  6247\n [5,] 13.840  4510  4507  4517\n [6,] 12.940   192   190   204\n [7,] 12.260  3214  3211  3218\n [8,] 10.800  1503  1499  1505\n [9,]  6.353 10565 10563 10570\n[10,]  4.949 12284 12283 12295\n[11,]  3.448  1654  1653  1668\n       [,1]  [,2]  [,3]  [,4]\n [1,] 5.784 10566 10563 10574\n [2,] 4.206 12284 12280 12286\n [3,] 3.342  4506  4503  4517\n [4,] 3.338  7966  7958  7973\n [5,] 3.283  1485  1483  1490\n [6,] 3.049  6383  6375  6388\n [7,] 2.664  6237  6232  6240\n [8,] 2.085  3217  3215  3225\n [9,] 1.812   192   190   199\n[10,] 1.384  9264  9260  9276\n[11,] 0.398 10719 10714 10724\n        [,1]  [,2]  [,3]  [,4]\n [1,] 15.070   186   184   194\n [2,] 11.760  9275  9272  9282\n [3,] 10.700  8258  8256  8263\n [4,]  9.060  7240  7238  7254\n [5,]  8.820  6234  6232  6246\n [6,]  6.789  4221  4217  4230\n [7,]  6.740 11283 11279 11295\n [8,]  6.706 12573 12571 12577\n [9,]  6.524  5227  5224  5238\n[10,]  5.963  3213  3211  3223\n[11,]  5.099 10274 10268 10283\n[12,]  4.934  2203  2200  2210\n[13,]  2.850  1233  1231  1239\n[14,]  2.215  1386  1383  1388\n[15,]  0.553  2348  2346  2355\n       [,1]  [,2]  [,3]  [,4]\n [1,] 5.393  7100  7097  7104\n [2,] 5.372  8108  8106  8130\n [3,] 5.241  1375  1369  1377\n [4,] 5.057  6381  6375  6402\n [5,] 5.001  3066  3062  3075\n [6,] 5.001  3357  3355  3378\n [7,] 4.836  4366  4363  4374\n [8,] 4.835  9410  9408  9430\n [9,] 4.675 10135 10133 10151\n[10,] 4.608  7384  7382  7395\n[11,] 4.603  4076  4073  4098\n[12,] 4.459 11136 11132 11139\n[13,] 4.428  8406  8403  8423\n[14,] 4.425  6091  6088  6100\n[15,] 4.206  5079  5073  5084\n[16,] 4.192  5364  5362  5385\n[17,] 4.178  9116  9114  9121\n[18,] 4.137 12140 12138 12142\n[19,] 4.020    46    44    62\n[20,] 3.849 10415 10412 10441\n[21,] 3.716  2350  2348  2357\n[22,] 3.433  2066  2065  2071\n[23,] 2.946 11430 11426 11432\n[24,] 0.817 12428 12426 12434\n[25,] 0.435   345   336   349\n       [,1]  [,2]  [,3]  [,4]\n [1,] 8.440 10138 10136 10160\n [2,] 8.160  8406  8403  8432\n [3,] 8.030  8107  8105  8114\n [4,] 7.796  9116  9115  9119\n [5,] 7.615  9410  9408  9435\n [6,] 7.592 11135 11132 11145\n [7,] 7.451 11430 11428 11435\n [8,] 7.258 10414 10412 10420\n [9,] 7.189 12136 12134 12139\n[10,] 5.036    48    44    63\n[11,] 4.523  7105  7097  7111\n[12,] 4.196  6384  6375  6405\n[13,] 4.172  7390  7383  7396\n[14,] 3.318 12431 12428 12435\n[15,] 3.158  1387  1382  1389\n[16,] 3.069  6095  6090  6104\n[17,] 2.873  5088  5084  5094\n[18,] 2.781  1101  1095  1106\n[19,] 2.741  4078  4071  4090\n[20,] 2.654   343   336   347\n[21,] 2.304  4370  4367  4373\n[22,] 2.222  5365  5361  5381\n[23,] 1.022  3359  3355  3368\n[24,] 0.681  3069  3063  3070\n[25,] 0.500  2084  2080  2086\n[26,] 0.364  2372  2366  2374\n      [,1]  [,2]  [,3]  [,4]\n[1,] 9.340   356   351   369\n[2,] 4.379 12445 12443 12448\n[3,] 3.929 10139 10136 10140\n[4,] 2.806  8410  8409  8412\n[5,] 1.968  2352  2350  2355\n[6,] 1.662  4369  4367  4374\n[7,] 0.697  6381  6375  6388\n       [,1]  [,2]  [,3]  [,4]\n[1,] 15.730 12424 12422 12427\n[2,] 11.350  6380  6375  6383\n[3,] 11.150   342   336   354\n[4,] 10.950  4369  4363  4370\n[5,] 10.610 10135 10132 10140\n[6,] 10.340  8394  8393  8397\n[7,]  8.660  2360  2358  2361\n[8,]  0.316  8541  8538  8544\n        [,1]  [,2]  [,3]  [,4]\n [1,] 10.870 10566 10563 10598\n [2,]  5.853   489   488   496\n [3,]  5.097   185   179   194\n [4,]  4.887 11281 11279 11286\n [5,]  4.781  1234  1231  1255\n [6,]  4.237   928   924   931\n [7,]  4.010  1917  1909  1919\n [8,]  3.575 12003 12001 12005\n [9,]  3.534 11568 11564 11573\n[10,]  3.457  8974  8972  8978\n[11,]  3.448  2493  2488  2496\n[12,]  3.356  2224  2223  2229\n[13,]  3.165  3221  3218  3227\n[14,]  3.110  2934  2931  2938\n[15,]  2.901  7964  7957  7967\n[16,]  2.672  5526  5525  5531\n[17,]  2.424  3513  3507  3516\n[18,]  2.413 10995 10992 10996\n[19,]  2.310  8259  8256  8264\n[20,]  2.189  5228  5227  5233\n[21,]  2.156 10275 10268 10292\n[22,]  2.126  4943  4939  4944\n[23,]  2.045  3933  3929  3936\n[24,]  2.003  4509  4506  4513\n[25,]  1.997  8540  8535  8545\n[26,]  1.717  6958  6955  6961\n[27,]  1.660  7245  7242  7249\n[28,]  1.461  1501  1493  1503\n[29,]  1.388  4238  4231  4241\n[30,]  1.059  6525  6522  6529\n[31,]  1.008  7531  7526  7533\n[32,]  0.743  9267  9263  9272\n[33,]  0.660 12282 12280 12286\n[34,]  0.408  5972  5971  5975\n[35,]  0.406  6245  6242  6247\n       [,1]  [,2]  [,3]  [,4]\n [1,] 4.630   183   180   204\n [2,] 2.741   487   486   492\n [3,] 1.672  6522  6520  6528\n [4,] 1.471  5508  5506  5512\n [5,] 1.314  6232  6230  6241\n [6,] 1.308  7533  7531  7547\n [7,] 1.254  5225  5222  5227\n [8,] 1.185  4511  4508  4517\n [9,] 1.171  4940  4938  4943\n[10,] 0.978 11289 11279 11294\n[11,] 0.913  4224  4222  4232\n[12,] 0.817  3501  3499  3505\n[13,] 0.802  7245  7242  7246\n[14,] 0.681  3218  3216  3220\n[15,] 0.646  3932  3929  3936\n[16,] 0.640  1235  1231  1237\n[17,] 0.559  2921  2918  2922\n[18,] 0.465  2492  2488  2494\n[19,] 0.396   921   914   923\n[20,] 0.318  1501  1498  1503\n[21,] 0.300  2205  2203  2209\n       [,1]  [,2]  [,3]  [,4]\n [1,] 8.950 10132 10126 10167\n [2,] 8.730 11134 11132 11147\n [3,] 8.720  9410  9408  9439\n [4,] 8.650  8109  8107  8116\n [5,] 8.540 11430 11427 11437\n [6,] 8.290 10414 10413 10420\n [7,] 7.997  8408  8403  8434\n [8,] 7.506  9116  9114  9120\n [9,] 7.354 12135 12133 12137\n[10,] 5.961  7097  7094  7103\n[11,] 5.761  6384  6375  6387\n[12,] 5.691  7383  7380  7387\n[13,] 5.179  6091  6089  6096\n[14,] 5.111  5363  5361  5369\n[15,] 5.083  3357  3353  3361\n[16,] 5.042  4365  4363  4368\n[17,] 4.824  5077  5073  5082\n[18,] 4.699  4074  4071  4075\n[19,] 4.588  2362  2361  2364\n[20,] 4.584  3085  3081  3112\n[21,] 4.507  2083  2081  2084\n[22,] 3.563  1344  1343  1347\n[23,] 3.017 12431 12428 12434\n[24,] 2.783  1068  1063  1070\n[25,] 2.137    47    45    53\n[26,] 1.512   330   328   340\n[27,] 1.151  1499  1497  1509\n        [,1]  [,2]  [,3]  [,4]\n [1,] 11.110    48    45    79\n [2,]  8.760  3065  3062  3071\n [3,]  6.260   343   336   346\n [4,]  5.702  3357  3355  3387\n [5,]  5.255  7099  7097  7110\n [6,]  4.877  4076  4073  4083\n [7,]  4.804  8407  8403  8423\n [8,]  3.986  5079  5073  5082\n [9,]  3.794  5365  5362  5373\n[10,]  3.685  9115  9113  9122\n[11,]  3.499  7391  7389  7403\n[12,]  3.260  6092  6090  6100\n[13,]  3.197 11135 11133 11152\n[14,]  3.184 10134 10132 10145\n[15,]  3.096 12136 12133 12138\n[16,]  3.019  6384  6375  6387\n[17,]  2.959 11429 11427 11440\n[18,]  2.946  8108  8106  8116\n[19,]  2.903  2351  2349  2358\n[20,]  2.819  9409  9407  9426\n[21,]  2.700 10415 10412 10432\n[22,]  2.461  1386  1382  1389\n[23,]  2.414  2061  2059  2065\n[24,]  1.990  4368  4366  4373\n[25,]  1.238  1057  1056  1060\n        [,1]  [,2]  [,3]  [,4]\n [1,] 12.110  3218  3216  3227\n [2,] 11.630  9274  9272  9316\n [3,] 11.290  7247  7244  7259\n [4,] 11.230  4223  4221  4227\n [5,] 10.830  6233  6230  6242\n [6,] 10.640 10276 10268 10298\n [7,] 10.250  5226  5222  5232\n [8,]  9.980  1233  1232  1241\n [9,]  9.680  8257  8255  8262\n[10,]  9.660 11282 11279 11283\n[11,]  9.590   188   186   196\n[12,]  9.400  2214  2213  2215\n[13,]  8.790 12569 12565 12571\n[14,]  7.928  1386  1382  1389\n[15,]  3.208 11441 11440 11449\n[16,]  0.841  2359  2357  2360\n        [,1]  [,2]  [,3]  [,4]\n [1,] 10.830  8259  8257  8262\n [2,] 10.550  3220  3218  3226\n [3,] 10.480  5228  5223  5229\n [4,] 10.470  9271  9269  9274\n [5,]  9.940  4238  4236  4240\n [6,]  9.640  6235  6232  6237\n [7,]  6.986 10276 10268 10278\n [8,]  6.703 11296 11290 11298\n [9,]  6.310  7246  7242  7258\n[10,]  3.466   190   187   197\n[11,]  2.399  1233  1231  1234\n[12,]  1.778  1386  1382  1390\n[13,]  1.663 10424 10422 10426\n[14,]  1.608 12578 12576 12582\n[15,]  1.334 11458 11457 11463\n[16,]  0.573  2204  2202  2206\n[17,]  0.374  9415  9414  9418\n[18,]  0.314  3371  3369  3375\n       [,1]  [,2]  [,3]  [,4]\n [1,] 5.545  1499  1497  1500\n [2,] 4.765  6239  6238  6240\n [3,] 4.270  6388  6387  6390\n [4,] 3.836  4510  4507  4513\n [5,] 3.151  9263  9260  9266\n [6,] 2.942  7966  7964  7973\n [7,] 2.457  3219  3217  3221\n [8,] 1.561   193   192   195\n [9,] 1.549  1644  1643  1647\n[10,] 0.572 12300 12298 12305\n        [,1]  [,2]  [,3]  [,4]\n [1,] 16.170 10575 10569 10579\n [2,] 15.880 12281 12275 12284\n [3,]  9.200  9256  9254  9257\n [4,]  8.550  7965  7957  7974\n [5,]  8.370  6386  6382  6392\n [6,]  8.350   195   192   203\n [7,]  7.722  6241  6237  6261\n [8,]  6.582  3220  3218  3226\n [9,]  5.977  4508  4505  4518\n[10,]  5.768 12439 12438 12440\n[11,]  5.726  1485  1482  1486\n[12,]  1.613  1657  1656  1658\n[13,]  1.267 10838 10837 10839\n[14,]  0.823   342   340   343\n[15,]  0.553  9405  9401  9409\n[16,]  0.534  4662  4661  4664\n[17,]  0.518 11414 11413 11415\n[18,]  0.492 12585 12580 12591\n[19,]  0.429  6533  6530  6538\n[20,]  0.374  3372  3369  3375\n        [,1]  [,2]  [,3]  [,4]\n [1,] 17.490  8407  8400  8414\n [2,] 12.280   343   340   344\n [3,]  9.470  6413  6410  6418\n [4,]  8.820  4400  4399  4401\n [5,]  8.650 10132 10126 10134\n [6,]  8.350 12430 12427 12433\n [7,]  7.858  2377  2376  2379\n [8,]  5.083   493   492   498\n [9,]  3.567  8552  8550  8571\n[10,]  0.979 12591 12588 12594\n[11,]  0.445   637   633   639\n[12,]  0.435 10380 10379 10381\n[13,]  0.367  2625  2622  2627\n        [,1]  [,2]  [,3]  [,4]\n [1,] 10.660  8400  8398  8403\n [2,]  8.350 12480 12478 12481\n [3,]  6.904 10134 10132 10153\n [4,]  3.943   356   353   360\n [5,]  3.054  2351  2349  2357\n [6,]  2.577  4368  4366  4373\n [7,]  1.261  6383  6375  6387\n [8,]  0.423 12657 12656 12658\n [9,]  0.367  2501  2498  2508\n\n\ndetermine a measuremnent noise threshhold as the mean of the min group + 10x stdev of the min group calculate the duraction above that treshhold, proportion of time wet, number of peaks, create rescaled newpulse data create newpulseWET where data below threshold are set to NA\n\n\nCode\nthresh &lt;- minS + 10*sdminS\nnewthresh &lt;- c()\nnewpulse &lt;- c()\nwetsum &lt;- c()\nwetprop &lt;- c()\nduration &lt;- c()\npeakcount &lt;- c()\nnewpulse &lt;- matrix(nrow=nrow(pulse),ncol=28)\nnewpulseWET &lt;- matrix(nrow=nrow(pulse),ncol=28)\nnewpulseWET2 &lt;- matrix(nrow=nrow(pulse),ncol=28)\npar(mfrow=c(2,5))\nfor(i in 1:28){\n  tryCatch({\n    newpulse[,i] &lt;- rescaleF(minS[i],maxS[i],minWC[as.numeric(as.factor(bc[i]))],\n                         maxWC[as.numeric(as.factor(bc[i]))],pulse[,i+1])\n    plot(newpulse[,i],type=\"l\",main=treat[i],cex.main=1,cex.lab=1,ylim=c(0,0.3))\n    newthresh[i] &lt;- rescaleF(minS[i],maxS[i],minWC[as.numeric(as.factor(bc[i]))],\n                             maxWC[as.numeric(as.factor(bc[i]))],thresh[i])\n    abline(h=newthresh[i],lwd=4,col=\"red\")\n    wetsum[i] &lt;- length(newpulse[,i][newpulse[,i]&gt;newthresh[i]])/6\n    wetprop[i] &lt;- wetsum[i]/(length(newpulse[,i])/6)\n    peakcount[i] &lt;- length(findpeaks(newpulse[,i],1,1,minpeakheight=newthresh[i],minpeakdistance = 144)[,1])\n    duration[i] &lt;- wetsum[i]/(counts[i])\n    newpulseWET[,i] &lt;- ifelse(newpulse[,i]&gt;newthresh[i],newpulse[,i],NA)\n    newpulseWET2[,i] &lt;- ifelse(newpulse[,i]&gt;2*newthresh[i],newpulse[,i],NA)\n  }, error=function(e){})\n}\n\n\n\n\n\n\n\n\nCode\nnewthresh &lt;- as.numeric(newthresh)\nduration &lt;- as.numeric(duration)\n\n# out.dat &lt;- cbind.data.frame(treatments$?..Sample_Num,treat,bc,wetsum,wetprop,duration)\n# write.csv(x = out.dat,file=\"Corrected_output.csv\")\n# \n# outVWC.dat &lt;- rbind.data.frame(treatments$?..Sample_Num,treat,bc,newpulse)\n# write.csv(x= outVWC.dat,file=\"Corrected_VWC.csv\")\n# \n# outWET.dat &lt;- rbind.data.frame(treatments$?..Sample_Num,treat,bc,newpulseWET)\n# write.csv(x= outWET.dat,file=\"WETcrust.csv\")\n\n\n\n\n\nrowmeans by treatments for timeseries with thresholds\n\n\nCode\ncyano1 &lt;- rowMeans(newpulse[,bc==\"cyano\"&treat==1.8])\ncyano2 &lt;- rowMeans(newpulse[,bc==\"cyano\"&treat==2.7])\ncyano5 &lt;- rowMeans(newpulse[,bc==\"cyano\"&treat==5.4])\ncyano7 &lt;- rowMeans(newpulse[,bc==\"cyano\"&treat==7.7])\ncyano10 &lt;- rowMeans(newpulse[,bc==\"cyano\"&treat==10.0])\n\nstr(newthresh)\n\n\n num [1:28] 0.0613 0.0428 0.0458 0.0333 0.0364 ...\n\n\nCode\nthreshc1 &lt;- mean(newthresh[bc==\"cyano\"&treat==1.8])\nthreshc2 &lt;- mean(newthresh[bc==\"cyano\"&treat==2.7])\nthreshc5 &lt;- mean(newthresh[bc==\"cyano\"&treat==5.4])\nthreshc7 &lt;- mean(newthresh[bc==\"cyano\"&treat==7.7])\nthreshc10 &lt;- mean(newthresh[bc==\"cyano\"&treat==10.0])\n\n\nmoss1 &lt;- rowMeans(newpulse[,bc==\"moss\"&treat==1.8])\nmoss2 &lt;- rowMeans(newpulse[,bc==\"moss\"&treat==2.7])\nmoss5 &lt;- rowMeans(newpulse[,bc==\"moss\"&treat==5.4])\nmoss7 &lt;- rowMeans(newpulse[,bc==\"moss\"&treat==7.7])\nmoss10 &lt;- rowMeans(newpulse[,bc==\"moss\"&treat==10.0])\nthreshm1 &lt;- mean(newthresh[bc==\"moss\"&treat==1.8])\nthreshm2 &lt;- mean(newthresh[bc==\"moss\"&treat==2.7])\nthreshm5 &lt;- mean(newthresh[bc==\"moss\"&treat==5.4])\nthreshm7 &lt;- mean(newthresh[bc==\"moss\"&treat==7.7])\nthreshm10 &lt;- mean(newthresh[bc==\"moss\"&treat==10.0])\n\nlength(cyano1)\n\n\n[1] 12673\n\n\nCode\nbeg &lt;- c(1,4001,8001)\nend &lt;- rep(length(cyano1),3)\npdf(\"CORRECTED_time series with threshold.pdf\",height=8, width=6, pointsize=10)\npar(mfrow=c(2,2),mar=c(4,4,1,0.5),pty=\"s\")\nfor(i in 1:1){\nplot(cyano1[beg[i]:end[i]],main=\"Cyano 1\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"water content\")\nabline(h=threshc1,col=\"red\",lwd=2)\nplot(cyano2[beg[i]:end[i]],main=\"Cyano 2\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"\")\nabline(h=threshc2,col=\"red\",lwd=2)\nplot(cyano5[beg[i]:end[i]],main=\"Cyano 5\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"\")\nabline(h=threshc5,col=\"red\",lwd=2)\nplot(cyano7[beg[i]:end[i]],main=\"Cyano 7\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"\")\nabline(h=threshc7,col=\"red\",lwd=2)\nplot(cyano10[beg[i]:end[i]],main=\"Cyano 10\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"\")\nabline(h=threshc10,col=\"red\",lwd=2)\n\nplot(moss1[beg[i]:end[i]],main=\"Moss 1\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"water content\")\nabline(h=threshm1,col=\"red\",lwd=2)\nplot(moss2[beg[i]:end[i]],main=\"Moss 2\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"\")\nabline(h=threshm2,col=\"red\",lwd=2)\nplot(moss5[beg[i]:end[i]],main=\"Moss 5\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"\")\nabline(h=threshm5,col=\"red\",lwd=2)\nplot(moss7[beg[i]:end[i]],main=\"Moss 7\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"\")\nabline(h=threshm7,col=\"red\",lwd=2)\nplot(moss10[beg[i]:end[i]],main=\"Moss 10\",type=\"l\",ylim=c(0,1),xlab=\"\",ylab=\"\")\nabline(h=threshm10,col=\"red\",lwd=2)\n}\ndev.off()\n\n\npng \n  2 \n\n\n\n\nCode\nstr(treat)\n\n\n num [1:28] 1.8 2.7 2.7 5.4 5.4 7.7 7.7 10 10 1.8 ...\n\n\nCode\nstr(bc)\n\n\n chr [1:28] \"moss\" \"cyano\" \"moss\" \"moss\" \"cyano\" \"moss\" \"cyano\" \"cyano\" ...\n\n\nCode\nbc &lt;- as.factor(bc)\n\n\n\n\nCode\npdf(\"CORRECTED_boxplot.pdf\",height=4, width=8, pointsize=10)\npar(mfrow=c(1,3),pty=\"s\")\nboxplot(duration~treat*bc,las=2,xlab=\"\",ylab=\"duration of  wetting event\")\nboxplot(wetsum~treat*bc,las=2,xlab=\"\",ylab=\"cumulative time wet\")\nboxplot(wetprop~treat*bc,las=2,xlab=\"\",ylab=\"proportion time wet\")\ndev.off()\n\n\npng \n  2 \n\n\nFOR DRY DOWN CURVES\n\n\nCode\ntimeinseries &lt;- matrix(nrow=nrow(pulse),ncol=28)\n\n\ncreate a timeinseries variable that determines when the start of each wetting sequence is, calls that 1, and then numbers sequentially until the start of the next wetting sequence\n\n\nCode\npar(mfrow=c(2,3))\nfor(i in 1:28){\n  for(j in 100:length(newpulseWET[,i])){\n    tryCatch({\n      timeinseries[j,i] &lt;- ifelse(is.na(mean(newpulseWET[(j-99):(j-1),i],na.rm=T)) & newpulseWET2[j,i]&gt;0,1,\n                                  ifelse(timeinseries[j-1,i]&gt;0,timeinseries[j-1,i]+1,NA))\n    }, error=function(e){})\n  }\n  plot(timeinseries[,i],newpulseWET[,i],main=i,ylim=c(0,max(newpulseWET[,i],na.rm=T)))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvectorize all measurements within a given treatment cyano\n\n\nCode\ncyano1 &lt;- as.vector(newpulse[,(bc==\"cyano\"&treat==1.8)])\n\n\nvectorize time series by a given treatment, convert from 10 minutes to hours this way of vectorization is a little silly, but this is just to create dry down curves, will need to add another column with treat and crust to do glm of time series to compare drydowns\n\n\nCode\ntc1 &lt;- as.vector(timeinseries[,(bc==\"cyano\"&treat==1.8)])/6\ncyano2 &lt;- as.vector(newpulse[,bc==\"cyano\"&treat==2.7])\ntc2 &lt;- as.vector(timeinseries[,bc==\"cyano\"&treat==2.7])/6\ncyano5 &lt;- as.vector(newpulse[,bc==\"cyano\"&treat==5.4])\ntc5 &lt;- as.vector(timeinseries[,bc==\"cyano\"&treat==5.4])/6\ncyano7 &lt;- as.vector(newpulse[,bc==\"cyano\"&treat==7.7])\ntc7 &lt;- as.vector(timeinseries[,bc==\"cyano\"&treat==7.7])/6\ncyano10 &lt;- as.vector(newpulse[,bc==\"cyano\"&treat==10.0])\ntc10 &lt;- as.vector(timeinseries[,bc==\"cyano\"&treat==10.0])/6\n\ncyano &lt;- c(cyano1,cyano2,cyano5,cyano7,cyano10)\ntc &lt;- c(tc1,tc2,tc5,tc7,tc10)\ncurveC &lt;- c(rep(\"c1\",length(cyano1)),rep(\"c2\",length(cyano2)),rep(\"c5\",length(cyano5)),rep(\"c7\",length(cyano7)),rep(\"c10\",length(cyano10)))\ncyano.tab &lt;- cbind(cyano,tc,curveC)\nwrite.csv(cyano.tab,file=\"cyanodrydown.csv\")\n\nfitC &lt;- drm(cyano~tc,curveid = curveC,fct=EXD.3(fixed=c(0.018,NA,NA)))\n#mselect(fitC, list(EXD.2(fixed=c(0.18,NA)),EXD.3(fixed=c(0.18,NA,NA))), linreg=TRUE, icfct=AIC)\nfitnoC &lt;- drm(cyano~tc,fct=EXD.3(fixed=c(0.018,NA,NA)))\n(anova(fitnoC,fitC))\n\n\n\n1st model\n fct:      EXD.3(fixed = c(0.018, NA, NA))\n pmodels: 1 (for all parameters)\n2nd model\n fct:      EXD.3(fixed = c(0.018, NA, NA))\n pmodels: curveC (for all parameters)\n\n\nANOVA table\n\n          ModelDf    RSS Df F value p value\n1st model   32860 452.29                   \n2nd model   32852 346.92  8  1247.3     0.0\n\n\nCode\ncompParm(fitC,strVal = c(\"e\"))\n\n\n\nComparison of parameter 'e' \n\n        Estimate Std. Error   t-value   p-value    \nc1/c2  0.9835777  0.0357544   -0.4593    0.6460    \nc1/c5  0.3141732  0.0140472  -48.8229 &lt; 2.2e-16 ***\nc1/c7  0.2413486  0.0079562  -95.3530 &lt; 2.2e-16 ***\nc1/c10 0.2468656  0.0083192  -90.5296 &lt; 2.2e-16 ***\nc2/c5  0.3194188  0.0133653  -50.9215 &lt; 2.2e-16 ***\nc2/c7  0.2453783  0.0071050 -106.2104 &lt; 2.2e-16 ***\nc2/c10 0.2509874  0.0074763 -100.1845 &lt; 2.2e-16 ***\nc5/c7  0.7682024  0.0299118   -7.7494 9.524e-15 ***\nc5/c10 0.7857628  0.0310850   -6.8920 5.602e-12 ***\nc7/c10 1.0228591  0.0261305    0.8748    0.3817    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nfitC2 &lt;- drm(cyano~tc,curveid = curveC,fct=EXD.3(fixed=c(minWC[1],maxWC[1],NA)))\nanova(fitC,fitC2)\n\n\n\n1st model\n fct:      EXD.3(fixed = c(minWC[1], maxWC[1], NA))\n2nd model\n fct:      EXD.3(fixed = c(0.018, NA, NA))\n\n\nANOVA table\n\n          ModelDf    RSS Df F value p value\n2nd model   32857 356.95                   \n1st model   32852 346.92  5   189.8     0.0\n\n\nusing DRC exponential decay model to fit drydown curves\n\n\nCode\npar(mfrow=c(2,3))\nplot(tc1,cyano1,xlim=c(0,60),ylim=c(0,1))\nfitC1 &lt;- drm(cyano1~tc1,fct=EXD.3(fixed=c(0,NA,NA)))\nplot(fitC1,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\nplot(tc2,cyano2,xlim=c(0,60),ylim=c(0,1))\nfitC2 &lt;- drm(cyano2~tc2,fct=EXD.3(fixed=c(0,NA,NA)))\nplot(fitC2,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\nplot(tc5,cyano5,xlim=c(0,60),ylim=c(0,1))\nfitC5 &lt;- drm(cyano5~tc5,fct=EXD.3(fixed=c(0,NA,NA)))\nplot(fitC5,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\nplot(tc7,cyano7,xlim=c(0,60),ylim=c(0,1))\nfitC7 &lt;- drm(cyano7~tc7,fct=EXD.3(fixed=c(0,NA,NA)))\nplot(fitC7,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\nplot(tc10,cyano10,xlim=c(0,60),ylim=c(0,1))\nfitC10 &lt;- drm(cyano10~tc10,fct=EXD.3(fixed=c(0,NA,NA)))\nplot(fitC10,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\n\n\n\n\n\nvectorize all measurements within a given treatment moss\n\n\nCode\nmoss1 &lt;- as.vector(newpulse[,(bc==\"moss\"&treat==1.8)])\ntm1 &lt;- as.vector(timeinseries[,(bc==\"moss\"&treat==1.8)])/6\nmoss2 &lt;- as.vector(newpulse[,bc==\"moss\"&treat==2.7])\ntm2 &lt;- as.vector(timeinseries[,bc==\"moss\"&treat==2.7])/6\nmoss5 &lt;- as.vector(newpulse[,bc==\"moss\"&treat==5.4])\ntm5 &lt;- as.vector(timeinseries[,bc==\"moss\"&treat==5.4])/6\nmoss7 &lt;- as.vector(newpulse[,bc==\"moss\"&treat==7.7])\ntm7 &lt;- as.vector(timeinseries[,bc==\"moss\"&treat==7.7])/6\nmoss10 &lt;- as.vector(newpulse[,bc==\"moss\"&treat==10.0])\ntm10 &lt;- as.vector(timeinseries[,bc==\"moss\"&treat==10.0])/6\n\n\nmoss &lt;- c(moss1,moss2,moss5,moss7,moss10)\ntm &lt;- c(tm1,tm2,tm5,tm7,tm10)\ncurveM &lt;- c(rep(\"m1\",length(cyano1)),rep(\"m2\",length(cyano2)),rep(\"m5\",length(cyano5)),rep(\"m7\",length(cyano7)),rep(\"m10\",length(cyano10)))\nfitM &lt;- drm(moss~tm,curveid = curveM,fct=EXD.3(fixed=c(0.0,NA,NA)))\nfitnoM &lt;- drm(moss~tm,fct=EXD.3(fixed=c(0.045,maxWC[2],NA)))\n(anova(fitnoM,fitM))\n\n\n\n1st model\n fct:      EXD.3(fixed = c(0.045, maxWC[2], NA))\n pmodels: 1 (for all parameters)\n2nd model\n fct:      EXD.3(fixed = c(0, NA, NA))\n pmodels: curveM (for all parameters)\n\n\nANOVA table\n\n          ModelDf    RSS Df F value p value\n1st model   25172 299.29                   \n2nd model   25163 210.69  9  1175.7     0.0\n\n\nCode\ncompParm(fitM,strVal = c(\"e\"))\n\n\n\nComparison of parameter 'e' \n\n        Estimate Std. Error   t-value   p-value    \nm1/m2  0.8727079  0.0397616   -3.2014  0.001369 ** \nm1/m5  0.5347803  0.0220057  -21.1409 &lt; 2.2e-16 ***\nm1/m7  0.2910071  0.0145645  -48.6797 &lt; 2.2e-16 ***\nm1/m10 0.2113051  0.0076124 -103.6064 &lt; 2.2e-16 ***\nm2/m5  0.6127827  0.0286449  -13.5179 &lt; 2.2e-16 ***\nm2/m7  0.3334531  0.0182541  -36.5150 &lt; 2.2e-16 ***\nm2/m10 0.2421259  0.0102433  -73.9876 &lt; 2.2e-16 ***\nm5/m7  0.5441620  0.0278224  -16.3838 &lt; 2.2e-16 ***\nm5/m10 0.3951252  0.0148221  -40.8090 &lt; 2.2e-16 ***\nm7/m10 0.7261168  0.0342030   -8.0076 1.276e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nallB &lt;- c(cyano, moss)\nallt &lt;- c(tc,tm)\nallcurve &lt;- c(curveC,curveM)\nfit &lt;- drm(allB~allt,curveid = allcurve,fct=EXD.3(fixed=c(0.031,NA,NA)))\n\n\nusing DRC EXD.2 (exponential decay) to fit dry down curves moss\n\n\nCode\npar(mfrow=c(2,3))\nplot(tm1,moss1,xlim=c(0,60),ylim=c(0,1))\nfitM1 &lt;- drm(moss1~tm1,fct=EXD.3(fixed=c(0.0,NA,NA)))\nplot(fitM1,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\nplot(tm2,moss2,xlim=c(0,60),ylim=c(0,1))\nfitM2 &lt;- drm(moss2~tm2,fct=EXD.3(fixed=c(0.0,NA,NA)))\nplot(fitM2,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\nplot(tm5,moss5,xlim=c(0,60),ylim=c(0,1))\nfitM5 &lt;- drm(moss5~tm5,fct=EXD.3(fixed=c(0.0,NA,NA)))\nplot(fitM5,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\nplot(tm7,moss7,xlim=c(0,60),ylim=c(0,1))\nfitM7 &lt;- drm(moss7~tm7,fct=EXD.3(fixed=c(0.0,NA,NA)))\nplot(fitM7,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\nplot(tm10,moss10,xlim=c(0,60),ylim=c(0,1))\nfitM10 &lt;- drm(moss10~tm10,fct=EXD.3(fixed=c(0.0,NA,NA)))\nplot(fitM10,log=\"\",add=T,col=\"red\",type=\"none\",lwd=2)\n\nED(fitC,respLev = c(mean(c(threshc1,threshc2,threshc5,threshc7,threshc10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                         Estimate Std. Error\ne:c1:0.0380011000165254   9.95673    0.27895\ne:c10:0.0380011000165254 41.74279    0.78179\ne:c2:0.0380011000165254  10.16351    0.23542\ne:c5:0.0380011000165254  29.22109    1.01824\ne:c7:0.0380011000165254  43.55455    0.75672\n\n\nCode\nED(fitC1,respLev = c(mean(c(threshc1,threshc2,threshc5,threshc7,threshc10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0380011000165254  9.54238    0.23705\n\n\nCode\nED(fitC2,respLev = c(mean(c(threshc1,threshc2,threshc5,threshc7,threshc10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0380011000165254   9.6367     0.1462\n\n\nCode\nED(fitC5,respLev = c(mean(c(threshc1,threshc2,threshc5,threshc7,threshc10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0380011000165254  30.4051     1.3651\n\n\nCode\nED(fitC7,respLev = c(mean(c(threshc1,threshc2,threshc5,threshc7,threshc10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0380011000165254 40.28443    0.82365\n\n\nCode\nED(fitC10,respLev = c(mean(c(threshc1,threshc2,threshc5,threshc7,threshc10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0380011000165254 37.49079    0.64069\n\n\nCode\n#ED(fitM,respLev = c(mean(c(threshm1,threshm2,threshm5,threshm7,threshm10))),type=\"absolute\")\nED(fitM1,respLev = c(mean(c(threshm1,threshm2,threshm5,threshm7,threshm10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0441357979603893  7.83556    0.17016\n\n\nCode\nED(fitM2,respLev = c(mean(c(threshm1,threshm2,threshm5,threshm7,threshm10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0441357979603893   8.4197     0.2214\n\n\nCode\nED(fitM5,respLev = c(mean(c(threshm1,threshm2,threshm5,threshm7,threshm10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0441357979603893 18.55620    0.60936\n\n\nCode\nED(fitM7,respLev = c(mean(c(threshm1,threshm2,threshm5,threshm7,threshm10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0441357979603893 20.90080    0.85398\n\n\nCode\nED(fitM10,respLev = c(mean(c(threshm1,threshm2,threshm5,threshm7,threshm10))),type=\"absolute\")\n\n\n\nEstimated effective doses\n\n                       Estimate Std. Error\ne:1:0.0441357979603893  35.1778     1.0773\n\n\n\n\n\nplotting dry down curves with detection threshold\n\n\nCode\npdf(\"drydowncurves3.pdf\",width = 6.50,height=4,pointsize=10)\npar(mfrow=c(1,2),pty=\"s\")\nplot(fitC1,log=\"\",col=1,type=\"none\",lwd=2,lty=\"dotted\",xlim=c(0,48),ylim=c(0,0.4),ylab=\"GWC\",xlab=\"Hours since watered\",main=\"Cyano\")\nplot(fitC2,log=\"\",add=T,col=2,type=\"none\",lwd=2,lty=\"dotted\")\nplot(fitC5,log=\"\",add=T,col=3,type=\"none\",lwd=2,lty=\"dotted\")\nplot(fitC7,log=\"\",add=T,col=4,type=\"none\",lwd=2,lty=\"dotted\")\nplot(fitC10,log=\"\",add=T,col=5,type=\"none\",lwd=2,lty=\"dotted\")\nplot(fitC1,log=\"\",add=T,col=1,type=\"none\",lwd=3,xlim=c(0,9.5))\nplot(fitC2,log=\"\",add=T,col=2,type=\"none\",lwd=3,xlim=c(0,9.6))\nplot(fitC5,log=\"\",add=T,col=3,type=\"none\",lwd=3,xlim=c(0,30.4))\nplot(fitC7,log=\"\",add=T,col=4,type=\"none\",lwd=3,xlim=c(0,40.2))\nplot(fitC10,log=\"\",add=T,col=5,type=\"none\",lwd=3,xlim=c(0,37.5))\nabline(h=mean(c(threshc1,threshc2,threshc5,threshc7,threshc10)))\nabline(v=c(9.5,9.6,30.4,40.2,37.5),col=c(1,2,3,4,5),lty=\"dashed\")\n\nplot(fitM1,log=\"\",col=1,type=\"none\",lwd=2,lty=\"dotted\",xlim=c(0,48),ylim=c(0,0.4),ylab=\"GWC\",xlab=\"Hours since watered\",main=\"Moss\")\nplot(fitM2,log=\"\",add=T,col=2,type=\"none\",lwd=2,lty=\"dotted\")\nplot(fitM5,log=\"\",add=T,col=3,type=\"none\",lwd=2,lty=\"dotted\")\nplot(fitM7,log=\"\",add=T,col=4,type=\"none\",lwd=2,lty=\"dotted\")\nplot(fitM10,log=\"\",add=T,col=5,type=\"none\",lwd=2,lty=\"dotted\")\nplot(fitM1,log=\"\",add=T,col=1,type=\"none\",lwd=3,xlim=c(0,7.8))\nplot(fitM2,log=\"\",add=T,col=2,type=\"none\",lwd=3,xlim=c(0,8.4))\nplot(fitM5,log=\"\",add=T,col=3,type=\"none\",lwd=3,xlim=c(0,18.5))\nplot(fitM7,log=\"\",add=T,col=4,type=\"none\",lwd=3,xlim=c(0,20.9))\nabline(h=mean(c(threshm1,threshm2,threshm5,threshm7,threshm10)))\nabline(v=c(7.8,8.4,18.5,20.9,35.2),col=c(1,2,3,4,5),lty=\"dashed\")\n\nlegend(\"topright\",legend=c(\"1.8\",\"2.7\",\"5.4\",\"7.7\",\"10.0\"),col=c(1,2,3,4,5),lty=\"solid\",lwd=2,bty=\"n\")\ndev.off()\n\n\npng \n  2 \n\n\nCode\nsummary(AIC(fitM1,fitM2,fitM5,fitM7,fitM10))\n\n\nWarning in AIC.default(fitM1, fitM2, fitM5, fitM7, fitM10): tous les modèles\nn'ont pas été ajustés sur le même nombre d'observations\n\n\n       df         AIC        \n Min.   :3   Min.   :-17100  \n 1st Qu.:3   1st Qu.:-11685  \n Median :3   Median : -9202  \n Mean   :3   Mean   :-10314  \n 3rd Qu.:3   3rd Qu.: -8485  \n Max.   :3   Max.   : -5099"
  },
  {
    "objectID": "experiment_2_initial_final_flux_analysis.html",
    "href": "experiment_2_initial_final_flux_analysis.html",
    "title": "experiment_2_initial_final_flux",
    "section": "",
    "text": "This code corresponds to Figure 3 and Table S2 in the manuscript The purpose of this code is to graph and analyze CO2 flux data (NSE, GPP, Respiration) from different biocrust types (Type) given different precipitation pulse treatments (Treat) at the beginning of the experiment (Initial) and the end of the experiment (Final)\n\n\nCode\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(mgcv)\n\n\nLe chargement a nécessité le package : nlme\n\nAttachement du package : 'nlme'\n\nL'objet suivant est masqué depuis 'package:dplyr':\n\n    collapse\n\nThis is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n\n\nCode\nlibrary(lme4)\n\n\nLe chargement a nécessité le package : Matrix\n\nAttachement du package : 'Matrix'\n\nLes objets suivants sont masqués depuis 'package:tidyr':\n\n    expand, pack, unpack\n\n\nAttachement du package : 'lme4'\n\nL'objet suivant est masqué depuis 'package:nlme':\n\n    lmList\n\n\nCode\nlibrary(sjPlot)\n\n\nInstall package \"strengejacke\" from GitHub (`devtools::install_github(\"strengejacke/strengejacke\")`) to load all sj-packages at once!\n\n\nCode\nlibrary(car)\n\n\nLe chargement a nécessité le package : carData\n\nAttachement du package : 'car'\n\nL'objet suivant est masqué depuis 'package:dplyr':\n\n    recode\n\nL'objet suivant est masqué depuis 'package:purrr':\n\n    some\n\n\nreading in and assigning flux data\n\n\nCode\nflux_data &lt;- read_csv(\"experiment_2_initial_final_flux.csv\") %&gt;% \n  mutate(Treat = as.numeric(Treat), Type = as.factor(Type), GPP_positive = as.numeric(GPP_positive)) \n\n\nRows: 99 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): Timepoint, Type, Date_IV, GPP_positive\ndbl (7): Treat, Rep, NSE_Lin_Flux_Light, Lin_FluxCV_Light, R_Dark_Flux_Light...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `GPP_positive = as.numeric(GPP_positive)`.\nCaused by warning:\n! NAs introduits lors de la conversion automatique\n\n\nCode\n# flux_data &lt;- read_csv(\"experiment_2_initial_final_flux.csv\") %&gt;% \n # mutate(Treat = as.numeric(Treat), Type = as.factor(Type), GPP_positive = as.numeric(GPP_positive)) #creates variables into factors and numeric for analysis\n\n\nrenaming flux values\n\n\nCode\nreal &lt;- rename(flux_data, GPP = \"GPP_positive\",\n              NSE = \"NSE_Lin_Flux_Light\",\n              Respiration = \"R_Dark_Flux_Light\")\n\n\nrenaming timmepoin values\n\n\nCode\nreal$Timepoint &lt;- factor(real$Timepoint, levels = c(\"Initial\", \"Final\"),\n                  labels = c(\"Initial Treatment\", \"Final Treatment\")\n)\n\n\ngrouping data to show in a single graph\n\n\nCode\nreal_combined &lt;- real %&gt;%\n  gather(Flux, Value, c(\"GPP\", \"Respiration\", \"NSE\")) %&gt;%\n  mutate(Value = as.numeric(Value))\n\n\ngraphing the initial vs final flux data for GPP, NSE, Respiration\n\n\nCode\nggplot(real_combined, aes(x = Treat, y = Value, color = Type, shape = Type), size = 2) + \n  geom_smooth(method = lm) + \n  facet_grid(Flux ~ Timepoint) +\n  geom_point(position = position_dodge(width = 0.5)) +\n  ylab('µmol CO2 m-2s-1') +\n  xlab('Watering amount (mm)') +\n  scale_x_continuous(breaks=c(1.8, 2.7, 5.4, 7.7, 10)) +\n  scale_color_manual(values = c(\"#fdbb84\", \"#2ca25f\")) +\n  theme_bw() +\n  theme(axis.title.x=element_text(size=12),\n        axis.text.x=element_text(size=12),\n        axis.title.y=element_text(size=12),\n        axis.text.y=element_text(size=12),\n        panel.grid.major = element_blank(),\n        axis.line = element_line(colour = \"black\"),\n        legend.title=element_text(size=12),\n        legend.text=element_text(size=12),\n        strip.text.x=element_text(size=12),\n        strip.text.y=element_text(size=12))\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nINITIAL TIMEPOINT ANALYSIS\n\n\nCode\nlm_pre &lt;- subset(real, Timepoint == \"Initial Treatment\")\nlm_pre$Treat &lt;- as.numeric(lm_pre$Treat)\nlm_pre$GPP &lt;- as.numeric(lm_pre$GPP)\n\n\nINITIAL GPP making a linear model for GPP at the initial timepoint\n\n\nCode\nlm_pre_GPP_model &lt;- lm(GPP ~ Type * Treat, data = lm_pre)\nsummary(lm_pre_GPP_model)\n\n\n\nCall:\nlm(formula = GPP ~ Type * Treat, data = lm_pre)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.30386 -0.26848  0.01618  0.29692  1.65455 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)     0.75887    0.23750   3.195  0.00253 **\nTypemoss        0.32277    0.33588   0.961  0.34159   \nTreat           0.09383    0.03765   2.492  0.01636 * \nTypemoss:Treat  0.01751    0.05324   0.329  0.74373   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5749 on 46 degrees of freedom\nMultiple R-squared:  0.3196,    Adjusted R-squared:  0.2753 \nF-statistic: 7.204 on 3 and 46 DF,  p-value: 0.000461\n\n\nCode\ntab_model(lm_pre_GPP_model)\n\n\n\n\n\n \nGPP\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n0.76\n0.28 – 1.24\n0.003\n\n\nType [moss]\n0.32\n-0.35 – 1.00\n0.342\n\n\nTreat\n0.09\n0.02 – 0.17\n0.016\n\n\nType [moss] × Treat\n0.02\n-0.09 – 0.12\n0.744\n\n\nObservations\n50\n\n\nR2 / R2 adjusted\n0.320 / 0.275\n\n\n\n\n\n\n\nCheck model assumptions\n\nNormality of residuals\n\n\n\nCode\nresiduals &lt;- residuals(lm_pre_GPP_model)\nshapiro_test &lt;- shapiro.test(residuals)  # Shapiro-Wilk test for normality\nprint(shapiro_test)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals\nW = 0.98636, p-value = 0.8283\n\n\nresiduals are normally distributed according to Shapiro-Wilk test\nPlot residuals\n\n\nCode\nggplot(data = data.frame(residuals = residuals), aes(x = residuals)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\")\n\n\n\n\n\nresiduals are roughly bell-shaped and do not show significant skew\n\nHomogeneity of variance Levene’s test requires a formula that includes the grouping variable\n\n\n\nCode\nlevene_test &lt;- leveneTest(Respiration ~ Type, data = lm_pre)  # Test for homogeneity of variances across Types\nprint(levene_test)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  2.1697 0.1473\n      48               \n\n\nAssumptions of homogeneity of variance hold\nPlot diagnostic plots for ANOVA\n\n\nCode\npar(mfrow = c(2, 2))\nplot(lm_pre_GPP_model)\n\n\n\n\n\nresiduals vs fitted show no clear pattern residuals fall along 45-degree angle random spread of points a few lines are outside of Cook’s distance line, but not too bad\nINITIAL NSE making a linear model for NSE at the initial timepoint\n\n\nCode\nlm_pre_NSE_model &lt;- lm(NSE ~ Type * Treat, data = lm_pre)\nsummary(lm_pre_NSE_model)\n\n\n\nCall:\nlm(formula = NSE ~ Type * Treat, data = lm_pre)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8557 -0.2777 -0.1235  0.3527  1.3178 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     0.93815    0.20419   4.594 3.38e-05 ***\nTypemoss       -0.35140    0.28877  -1.217    0.230    \nTreat           0.04023    0.03237   1.243    0.220    \nTypemoss:Treat  0.06351    0.04578   1.387    0.172    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4942 on 46 degrees of freedom\nMultiple R-squared:  0.2044,    Adjusted R-squared:  0.1525 \nF-statistic: 3.939 on 3 and 46 DF,  p-value: 0.01391\n\n\nCode\ntab_model(lm_pre_NSE_model)\n\n\n\n\n\n \nNSE\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n0.94\n0.53 – 1.35\n&lt;0.001\n\n\nType [moss]\n-0.35\n-0.93 – 0.23\n0.230\n\n\nTreat\n0.04\n-0.02 – 0.11\n0.220\n\n\nType [moss] × Treat\n0.06\n-0.03 – 0.16\n0.172\n\n\nObservations\n50\n\n\nR2 / R2 adjusted\n0.204 / 0.153\n\n\n\n\n\n\n\nCheck model assumptions\n\nNormality of residuals\n\n\n\nCode\nresiduals &lt;- residuals(lm_pre_NSE_model)\nshapiro_test &lt;- shapiro.test(residuals)  # Shapiro-Wilk test for normality\nprint(shapiro_test)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals\nW = 0.973, p-value = 0.3053\n\n\nresiduals are normally distributed according to Shapiro-Wilk test\nPlot residuals\n\n\nCode\nggplot(data = data.frame(residuals = residuals), aes(x = residuals)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\")\n\n\n\n\n\nresiduals are roughly bell-shaped and do not show significant skew\n\nHomogeneity of variance Levene’s test requires a formula that includes the grouping variable\n\n\n\nCode\nlevene_test &lt;- leveneTest(NSE ~ Type, data = lm_pre)  # Test for homogeneity of variances across Types\nprint(levene_test)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(&gt;F)  \ngroup  1  2.8187 0.09967 .\n      48                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAssumptions of homogeneity of variance hold\nPlot diagnostic plots for ANOVA\n\n\nCode\npar(mfrow = c(2, 2))\nplot(lm_pre_NSE_model)\n\n\n\n\n\nresiduals vs fitted show no clear pattern residuals fall along 45-degree angle random spread of points a few lines are outside of Cook’s distance line, but not too bad\nINITIAL RESPIRATION making a linear model for R at the initial timepoint\n\n\nCode\nlm_pre_R_model &lt;- lm(Respiration ~ Type * Treat, data = lm_pre)\nsummary(lm_pre_R_model)\n\n\n\nCall:\nlm(formula = Respiration ~ Type * Treat, data = lm_pre)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.62254 -0.27521 -0.01446  0.21612  0.81155 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     1.69701    0.16107  10.536 7.53e-14 ***\nTypemoss       -0.02863    0.22778  -0.126   0.9005    \nTreat           0.13406    0.02553   5.251 3.77e-06 ***\nTypemoss:Treat  0.08102    0.03611   2.244   0.0297 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3898 on 46 degrees of freedom\nMultiple R-squared:  0.7106,    Adjusted R-squared:  0.6917 \nF-statistic: 37.65 on 3 and 46 DF,  p-value: 1.926e-12\n\n\nCode\ntab_model(lm_pre_R_model)\n\n\n\n\n\n \nRespiration\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n1.70\n1.37 – 2.02\n&lt;0.001\n\n\nType [moss]\n-0.03\n-0.49 – 0.43\n0.901\n\n\nTreat\n0.13\n0.08 – 0.19\n&lt;0.001\n\n\nType [moss] × Treat\n0.08\n0.01 – 0.15\n0.030\n\n\nObservations\n50\n\n\nR2 / R2 adjusted\n0.711 / 0.692\n\n\n\n\n\n\n\nCheck model assumptions\n\nNormality of residuals\n\n\n\nCode\nresiduals &lt;- residuals(lm_pre_R_model)\nshapiro_test &lt;- shapiro.test(residuals)  # Shapiro-Wilk test for normality\nprint(shapiro_test)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals\nW = 0.97061, p-value = 0.2451\n\n\nresiduals are normally distributed according to Shapiro-Wilk test\nPlot residuals\n\n\nCode\nggplot(data = data.frame(residuals = residuals), aes(x = residuals)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\")\n\n\n\n\n\nresiduals are roughly bell-shaped and do not show significant skew\n\nHomogeneity of variance Levene’s test requires a formula that includes the grouping variable\n\n\n\nCode\nlevene_test &lt;- leveneTest(Respiration ~ Type, data = lm_pre)  # Test for homogeneity of variances across Types\nprint(levene_test)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  2.1697 0.1473\n      48               \n\n\nAssumptions of homogeneity of variance hold\nPlot diagnostic plots for ANOVA\n\n\nCode\npar(mfrow = c(2, 2))\nplot(lm_pre_R_model)\n\n\n\n\n\nresiduals vs fitted show no clear pattern residuals fall along 45-degree angle random spread of points a few lines are outside of Cook’s distance line, but not too bad\nFINAL TREATMENT ANALYSIS\n\n\nCode\nlm_post &lt;- subset(real, Timepoint == \"Final Treatment\")\nlm_post$Treat &lt;- as.numeric(lm_post$Treat)\n\n\nFINAL GPP making a linear model for GPP at the final timepoint\n\n\nCode\nlm_post_GPP_model &lt;- lm(GPP ~ Type * Treat, data = lm_post)\nsummary(lm_post_GPP_model)\n\n\n\nCall:\nlm(formula = GPP ~ Type * Treat, data = lm_post)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.72777 -0.16638 -0.02718  0.20282  0.40565 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     1.01166    0.10409   9.719  1.6e-12 ***\nTypemoss        0.30569    0.14474   2.112   0.0404 *  \nTreat           0.03477    0.01623   2.143   0.0377 *  \nTypemoss:Treat  0.03254    0.02286   1.423   0.1617    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2433 on 44 degrees of freedom\n  (1 observation effacée parce que manquante)\nMultiple R-squared:  0.6064,    Adjusted R-squared:  0.5796 \nF-statistic:  22.6 on 3 and 44 DF,  p-value: 5.229e-09\n\n\nCode\ntab_model(lm_post_GPP_model)\n\n\n\n\n\n \nGPP\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n1.01\n0.80 – 1.22\n&lt;0.001\n\n\nType [moss]\n0.31\n0.01 – 0.60\n0.040\n\n\nTreat\n0.03\n0.00 – 0.07\n0.038\n\n\nType [moss] × Treat\n0.03\n-0.01 – 0.08\n0.162\n\n\nObservations\n48\n\n\nR2 / R2 adjusted\n0.606 / 0.580\n\n\n\n\n\n\n\nCheck model assumptions\n\nNormality of residuals\n\n\n\nCode\nresiduals &lt;- residuals(lm_post_GPP_model)\nshapiro_test &lt;- shapiro.test(residuals)  # Shapiro-Wilk test for normality\nprint(shapiro_test)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals\nW = 0.94983, p-value = 0.03937\n\n\nresiduals are mostly normally distributed according to Shapiro-Wilk test\nPlot residuals\n\n\nCode\nggplot(data = data.frame(residuals = residuals), aes(x = residuals)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\")\n\n\n\n\n\nthere is a bit of skew but linear models are robust to minor deviation\n\nHomogeneity of variance\n\nLevene’s test requires a formula that includes the grouping variable\n\n\nCode\nlevene_test &lt;- leveneTest(GPP ~ Type, data = lm_post)  # Test for homogeneity of variances across Types\nprint(levene_test)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  2.5941 0.1141\n      46               \n\n\nAssumptions of homogeneity of variance hold\nPlot diagnostic plots for ANOVA\n\n\nCode\npar(mfrow = c(2, 2))\nplot(lm_post_GPP_model)\n\n\n\n\n\nresiduals vs fitted show no clear pattern residuals fall along 45-degree angle random spread of points a few lines are outside of Cook’s distance line, but not too bad\nFINAL NSE making a linear model for NSE at the final timepoint\n\n\nCode\nlm_post_NSE_model &lt;- lm(NSE ~ Type * Treat, data = lm_post)\nsummary(lm_post_NSE_model)\n\n\n\nCall:\nlm(formula = NSE ~ Type * Treat, data = lm_post)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.37224 -0.10934 -0.01788  0.05109  0.92318 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     0.42611    0.09438   4.515 4.53e-05 ***\nTypemoss       -0.21090    0.13350  -1.580   0.1212    \nTreat           0.01432    0.01496   0.957   0.3435    \nTypemoss:Treat  0.04963    0.02127   2.333   0.0242 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2284 on 45 degrees of freedom\nMultiple R-squared:  0.3031,    Adjusted R-squared:  0.2567 \nF-statistic: 6.525 on 3 and 45 DF,  p-value: 0.0009276\n\n\nCode\ntab_model(lm_post_NSE_model)\n\n\n\n\n\n \nNSE\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n0.43\n0.24 – 0.62\n&lt;0.001\n\n\nType [moss]\n-0.21\n-0.48 – 0.06\n0.121\n\n\nTreat\n0.01\n-0.02 – 0.04\n0.344\n\n\nType [moss] × Treat\n0.05\n0.01 – 0.09\n0.024\n\n\nObservations\n49\n\n\nR2 / R2 adjusted\n0.303 / 0.257\n\n\n\n\n\n\n\nCheck model assumptions 1. Normality of residuals\n\n\nCode\nresiduals &lt;- residuals(lm_post_NSE_model)\nshapiro_test &lt;- shapiro.test(residuals)  # Shapiro-Wilk test for normality\nprint(shapiro_test)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals\nW = 0.80656, p-value = 1.511e-06\n\n\nresiduals are not normally distributed according to shapiro-wilks\nPlot residuals\n\n\nCode\nggplot(data = data.frame(residuals = residuals), aes(x = residuals)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\")\n\n\n\n\n\nIt looks like there are two data points skewing the data, the model is robust enough to deal with two skewed points\n\nHomogeneity of variance Levene’s test requires a formula that includes the grouping variable\n\n\n\nCode\nlevene_test &lt;- leveneTest(NSE ~ Type, data = lm_post)  # Test for homogeneity of variances across Types\nprint(levene_test)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  0.9739 0.3288\n      47               \n\n\nAssumptions of homogeneity of variance hold\nPlot diagnostic plots for ANOVA\n\n\nCode\npar(mfrow = c(2, 2))\nplot(lm_post_NSE_model)\n\n\n\n\n\nresiduals vs fitted show no clear pattern residuals fall along 45-degree angle random spread of points a few lines are outside of Cook’s distance line, but not too bad\nFINAL RESPIRATION making a linear model for R at the final timepoint\n\n\nCode\nlm_post_R_model &lt;- lm(Respiration ~ Type * Treat, data = lm_post)\nsummary(lm_post_R_model)\n\n\n\nCall:\nlm(formula = Respiration ~ Type * Treat, data = lm_post)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.45402 -0.13594 -0.01654  0.17182  0.34733 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     1.33131    0.09073  14.674  &lt; 2e-16 ***\nTypemoss        0.20125    0.12616   1.595  0.11782    \nTreat           0.06115    0.01414   4.323 8.67e-05 ***\nTypemoss:Treat  0.07011    0.01993   3.518  0.00102 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2121 on 44 degrees of freedom\n  (1 observation effacée parce que manquante)\nMultiple R-squared:  0.814, Adjusted R-squared:  0.8013 \nF-statistic: 64.18 on 3 and 44 DF,  p-value: 4.159e-16\n\n\nCode\ntab_model(lm_post_R_model)\n\n\n\n\n\n \nRespiration\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n1.33\n1.15 – 1.51\n&lt;0.001\n\n\nType [moss]\n0.20\n-0.05 – 0.46\n0.118\n\n\nTreat\n0.06\n0.03 – 0.09\n&lt;0.001\n\n\nType [moss] × Treat\n0.07\n0.03 – 0.11\n0.001\n\n\nObservations\n48\n\n\nR2 / R2 adjusted\n0.814 / 0.801\n\n\n\n\n\n\n\nCheck model assumptions\n\nNormality of residuals\n\n\n\nCode\nresiduals &lt;- residuals(lm_post_R_model)\nshapiro_test &lt;- shapiro.test(residuals)  # Shapiro-Wilk test for normality\nprint(shapiro_test)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals\nW = 0.96723, p-value = 0.1972\n\n\nresiduals are mostly normally distributed according to Shapiro-Wilk test\nPlot residuals\n\n\nCode\nggplot(data = data.frame(residuals = residuals), aes(x = residuals)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\")\n\n\n\n\n\nthere is a bit of skew but linear models are robust to minor deviation\n\nHomogeneity of variance\n\nLevene’s test requires a formula that includes the grouping variable\n\n\nCode\nlevene_test &lt;- leveneTest(Respiration ~ Type, data = lm_post)  # Test for homogeneity of variances across Types\nprint(levene_test)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(&gt;F)  \ngroup  1  6.5539 0.01382 *\n      46                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAssumptions of homogeneity of variance are not met, but its not too bad\nPlot diagnostic plots for ANOVA\n\n\nCode\npar(mfrow = c(2, 2))\nplot(lm_post_R_model)\n\n\n\n\n\nresiduals vs fitted show no clear pattern residuals fall along 45-degree angle random spread of points a few lines are outside of Cook’s distance line, but not too bad"
  }
]